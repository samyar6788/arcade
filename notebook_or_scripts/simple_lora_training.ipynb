{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple LoRA Training with Custom Dataset\n",
        "## Following Machine Learning Mastery Blog\n",
        "\n",
        "This notebook follows the blog post step-by-step to train a LoRA on your custom dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries as mentioned in the blog\n",
        "%pip install git+https://github.com/huggingface/diffusers\n",
        "%pip install accelerate wandb\n",
        "%pip install -r https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/requirements.txt\n",
        "\n",
        "# Configure accelerate\n",
        "!accelerate config default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test imports as suggested in the blog\n",
        "import wandb\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, AutoPipelineForText2Image\n",
        "from huggingface_hub import model_info\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Download Training Script\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the training script as mentioned in the blog\n",
        "!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora.py\n",
        "\n",
        "print(\"‚úÖ Training script downloaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare Your Dataset\n",
        "\n",
        "Create a directory with:\n",
        "- Your images (JPG, PNG, etc.)\n",
        "- A `metadata.csv` file with columns: `file_name`, `caption`\n",
        "\n",
        "Example metadata.csv:\n",
        "```\n",
        "file_name,caption\n",
        "image_0.png,a drawing of a green pokemon with red eyes\n",
        "image_1.png,a green and yellow toy with a red nose\n",
        "image_2.png,a red and white ball with an angry look on its face\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your dataset path here\n",
        "DATASET_PATH = \"./my_custom_dataset\"  # Change this to your dataset directory\n",
        "\n",
        "import os\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    print(f\"‚úÖ Dataset found at: {DATASET_PATH}\")\n",
        "    \n",
        "    # Check for metadata.csv\n",
        "    metadata_file = os.path.join(DATASET_PATH, \"metadata.csv\")\n",
        "    if os.path.exists(metadata_file):\n",
        "        print(\"‚úÖ metadata.csv found\")\n",
        "        \n",
        "        # Show dataset info\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(metadata_file)\n",
        "        print(f\"üìä Dataset has {len(df)} images\")\n",
        "        print(\"Sample entries:\")\n",
        "        print(df.head())\n",
        "    else:\n",
        "        print(\"‚ùå metadata.csv not found - please create it!\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset directory not found: {DATASET_PATH}\")\n",
        "    print(\"Please create your dataset directory with images and metadata.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Configure Training Parameters\n",
        "\n",
        "Following the blog's example parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration following the blog\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
        "OUTPUT_DIR = \"./finetune_lora/my_custom\"\n",
        "HUB_MODEL_ID = \"my-custom-lora\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Start Training\n",
        "\n",
        "This follows the exact command structure from the blog:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training command following the blog exactly\n",
        "training_command = f\"\"\"\n",
        "accelerate launch --mixed_precision=\"bf16\" train_text_to_image_lora.py \\\\\n",
        "  --pretrained_model_name_or_path={MODEL_NAME} \\\\\n",
        "  --dataset_name={DATASET_PATH} \\\\\n",
        "  --dataloader_num_workers=8 \\\\\n",
        "  --resolution=512 \\\\\n",
        "  --center_crop \\\\\n",
        "  --random_flip \\\\\n",
        "  --train_batch_size=1 \\\\\n",
        "  --gradient_accumulation_steps=4 \\\\\n",
        "  --max_train_steps=1000 \\\\\n",
        "  --learning_rate=1e-04 \\\\\n",
        "  --max_grad_norm=1 \\\\\n",
        "  --lr_scheduler=\"cosine\" \\\\\n",
        "  --lr_warmup_steps=0 \\\\\n",
        "  --output_dir={OUTPUT_DIR} \\\\\n",
        "  --checkpointing_steps=500 \\\\\n",
        "  --caption_column=\"caption\" \\\\\n",
        "  --validation_prompt=\"A beautiful artwork in my custom style.\" \\\\\n",
        "  --seed=1337\n",
        "\"\"\"\n",
        "\n",
        "print(\"Training command:\")\n",
        "print(training_command)\n",
        "print(\"\\n‚ö†Ô∏è This will take several hours to complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actually run the training (uncomment the line below)\n",
        "# !{training_command}\n",
        "\n",
        "print(\"Uncomment the line above to start training!\")\n",
        "print(\"Training will create checkpoints every 500 steps in:\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Test Your Trained LoRA\n",
        "\n",
        "Following the blog's usage example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: Manual loading (from the blog)\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from huggingface_hub import model_info\n",
        "import torch\n",
        "\n",
        "# Check if LoRA was trained\n",
        "lora_file = os.path.join(OUTPUT_DIR, \"pytorch_lora_weights.safetensors\")\n",
        "\n",
        "if os.path.exists(lora_file):\n",
        "    print(f\"‚úÖ LoRA found: {lora_file}\")\n",
        "    \n",
        "    # Load base model\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(MODEL_NAME, torch_dtype=torch.float16)\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "    \n",
        "    # Load LoRA weights\n",
        "    pipe.unet.load_attn_procs(OUTPUT_DIR)\n",
        "    pipe.to(\"cuda\")\n",
        "    \n",
        "    print(\"‚úÖ LoRA loaded successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå LoRA file not found. Complete training first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 2: Auto pipeline (easier method from the blog)\n",
        "if os.path.exists(lora_file):\n",
        "    pipeline = AutoPipelineForText2Image.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float16\n",
        "    ).to(\"cuda\")\n",
        "    \n",
        "    pipeline.load_lora_weights(OUTPUT_DIR, weight_name=\"pytorch_lora_weights.safetensors\")\n",
        "    \n",
        "    # Generate test image\n",
        "    image = pipeline(\"A beautiful artwork in my custom style\").images[0]\n",
        "    \n",
        "    # Display the image\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Generated with Custom LoRA\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Save the image\n",
        "    image.save(\"custom_lora_test.png\")\n",
        "    print(\"‚úÖ Test image saved as: custom_lora_test.png\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Complete training first!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Done! üéâ\n",
        "\n",
        "Your LoRA is now trained and ready to use. The main file is:\n",
        "- `pytorch_lora_weights.safetensors` in your output directory\n",
        "\n",
        "You can use this LoRA file in:\n",
        "- Python code (as shown above)\n",
        "- Automatic1111 WebUI\n",
        "- ComfyUI  \n",
        "- Any other Stable Diffusion interface that supports LoRA\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
