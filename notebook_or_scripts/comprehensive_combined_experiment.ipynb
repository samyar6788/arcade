{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ2GLSQ5BWc6"
      },
      "source": [
        "# ðŸŽ¯ Comprehensive Combined Experiment: Sampler + Strategy + CFG Analysis\n",
        "\n",
        "## Ultimate Goal\n",
        "Perform the most comprehensive analysis of Stable Diffusion jewelry generation by testing:\n",
        "1. **Technical Parameters**: Models, samplers, steps, CFG scales (from sampler notebook)\n",
        "2. **Prompt Engineering**: Different weighting strategies (from strategy notebook)\n",
        "3. **Quality Metrics**: CLIP confidence + LAION aesthetic scores\n",
        "\n",
        "## Complete Testing Framework\n",
        "- **Models**: 3 (SDXL, SD 1.5, SD 2.1)\n",
        "- **Samplers**: 5 (DDIM, DPMSolver++, DDPM, Euler, Euler_Ancestral)\n",
        "- **Steps**: 6 (15, 20, 25, 30, 35, 40)\n",
        "- **CFG Scales**: 3 (5.0, 7.5, 10.0)\n",
        "- **Strategies**: 6 (baseline, light_compel, medium_compel, heavy_compel, numeric_weights, style_focus)\n",
        "- **Prompts**: 8 jewelry prompts\n",
        "- **Total combinations**: 3 Ã— 5 Ã— 6 Ã— 3 Ã— 6 Ã— 8 = **12,960 generations**\n",
        "\n",
        "## Evaluation Metrics\n",
        "- **CLIP Analysis**: Semantic matching with jewelry-specific labels\n",
        "- **LAION Aesthetic Scores**: Visual appeal on 0-10 scale\n",
        "- **Generation Performance**: Time, success rate, resource usage\n",
        "- **Multi-dimensional Analysis**: Cross-parameter interactions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwUe27ecywJ_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wDGv54OMBp4r"
      },
      "outputs": [],
      "source": [
        "!pip install compel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K00EgQ3GBWc7"
      },
      "outputs": [],
      "source": [
        "# Setup - Ultimate Combined Testing Framework\n",
        "import torch\n",
        "from diffusers import (\n",
        "    StableDiffusionXLPipeline, StableDiffusionPipeline,\n",
        "    DDIMScheduler, DPMSolverMultistepScheduler, DDPMScheduler,\n",
        "    EulerDiscreteScheduler, EulerAncestralDiscreteScheduler\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "from itertools import product\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"ðŸ–¥ï¸ Device: {device}\")\n",
        "\n",
        "# Enhanced Model Configuration with Multiple CFG Scales\n",
        "MODEL_CONFIGS = {\n",
        "    \"SDXL\": {\n",
        "        \"model_id\": \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        \"resolution\": 768,\n",
        "        \"pipeline_class\": StableDiffusionXLPipeline,\n",
        "        \"default_cfg\": 5.0\n",
        "    },\n",
        "    \"SD15\": {\n",
        "        \"model_id\": \"runwayml/stable-diffusion-v1-5\",\n",
        "        \"resolution\": 512,\n",
        "        \"pipeline_class\": StableDiffusionPipeline,\n",
        "        \"default_cfg\": 7.5\n",
        "    },\n",
        "    \"SD21\": {\n",
        "        \"model_id\": \"stabilityai/stable-diffusion-2-1\",\n",
        "        \"resolution\": 768,\n",
        "        \"pipeline_class\": StableDiffusionPipeline,\n",
        "        \"default_cfg\": 7.5\n",
        "    }\n",
        "}\n",
        "\n",
        "# Enhanced Sampler Configuration with Euler Methods\n",
        "SAMPLER_CONFIGS = {\n",
        "    \"DDIM\": {\n",
        "        \"scheduler_class\": DDIMScheduler,\n",
        "        \"description\": \"Deterministic, good quality, moderate speed\"\n",
        "    },\n",
        "    \"DPMSolver++\": {\n",
        "        \"scheduler_class\": DPMSolverMultistepScheduler,\n",
        "        \"description\": \"Fast convergence, excellent quality, newer method\"\n",
        "    },\n",
        "    \"DDPM\": {\n",
        "        \"scheduler_class\": DDPMScheduler,\n",
        "        \"description\": \"Original method, high quality, slower\"\n",
        "    },\n",
        "    \"Euler\": {\n",
        "        \"scheduler_class\": EulerDiscreteScheduler,\n",
        "        \"description\": \"Fast, simple ODE solver, good for fewer steps\"\n",
        "    },\n",
        "    \"Euler_Ancestral\": {\n",
        "        \"scheduler_class\": EulerAncestralDiscreteScheduler,\n",
        "        \"description\": \"Euler with randomness, non-deterministic, creative\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Extended Testing Parameters\n",
        "STEP_COUNTS = [20, 30, 40, 50]\n",
        "CFG_SCALES = [5.0, 7.5, 9.0]  # NEW: Multiple CFG scales to test\n",
        "\n",
        "# Prompt Engineering Strategies (from strategy notebook)\n",
        "STRATEGY_CONFIGS = {\n",
        "    \"baseline\": {\n",
        "        \"description\": \"Original prompt unchanged\",\n",
        "        \"modifier\": lambda prompt: prompt\n",
        "    },\n",
        "    \"light_compel\": {\n",
        "        \"description\": \"Light emphasis with single +\",\n",
        "        \"modifier\": lambda prompt: apply_light_compel(prompt)\n",
        "    },\n",
        "    \"medium_compel\": {\n",
        "        \"description\": \"Medium emphasis with double ++\",\n",
        "        \"modifier\": lambda prompt: apply_medium_compel(prompt)\n",
        "    },\n",
        "    \"heavy_compel\": {\n",
        "        \"description\": \"Heavy emphasis with triple +++\",\n",
        "        \"modifier\": lambda prompt: apply_heavy_compel(prompt)\n",
        "    },\n",
        "    \"numeric_weights\": {\n",
        "        \"description\": \"Numerical weight emphasis (word:1.2)\",\n",
        "        \"modifier\": lambda prompt: apply_numeric_weights(prompt)\n",
        "    },\n",
        "    \"style_focus\": {\n",
        "        \"description\": \"Enhanced photography/style terms\",\n",
        "        \"modifier\": lambda prompt: apply_style_focus(prompt)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Test prompts (jewelry-focused)\n",
        "test_prompts = [\n",
        "    \"channel-set diamond eternity band, 2 mm width, hammered 18k yellow gold, product-only white background\",\n",
        "    \"14k rose-gold threader earrings, bezel-set round lab diamond ends, lifestyle macro shot, soft natural light\",\n",
        "    \"organic cluster ring with mixed-cut sapphires and diamonds, brushed platinum finish, modern aesthetic\",\n",
        "    \"modern signet ring, oval face, engraved gothic initial 'M', high-polish sterling silver, subtle reflection\",\n",
        "    \"delicate gold huggie hoops, contemporary styling, isolated on neutral background\",\n",
        "    \"stack of three slim rings: twisted gold, plain platinum, black rhodium pavÃ©, editorial lighting\",\n",
        "    \"bypass ring with stones on it, with refined simplicity and intentionally crafted for everyday wear\",\n",
        "    \"A solid gold cuff bracelet with blue sapphire, with refined simplicity and intentionally crafted for everyday wear\"\n",
        "]\n",
        "\n",
        "print(f\"ðŸ“Š Complete Testing Configuration:\")\n",
        "print(f\"  â€¢ Models: {list(MODEL_CONFIGS.keys())}\")\n",
        "print(f\"  â€¢ Samplers: {list(SAMPLER_CONFIGS.keys())}\")\n",
        "print(f\"  â€¢ Step counts: {STEP_COUNTS}\")\n",
        "print(f\"  â€¢ CFG scales: {CFG_SCALES}\")\n",
        "print(f\"  â€¢ Strategies: {list(STRATEGY_CONFIGS.keys())}\")\n",
        "print(f\"  â€¢ Prompts: {len(test_prompts)}\")\n",
        "\n",
        "total_combinations = (len(MODEL_CONFIGS) * len(SAMPLER_CONFIGS) *\n",
        "                     len(STEP_COUNTS) * len(CFG_SCALES) *\n",
        "                     len(STRATEGY_CONFIGS) * len(test_prompts))\n",
        "print(f\"  â€¢ Total generations: {total_combinations:,}\")\n",
        "print(f\"  â€¢ Estimated time: ~{total_combinations * 0.5 / 60:.0f}-{total_combinations * 1 / 60:.0f} hours\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"/content/drive/MyDrive/arcade_comp_results/combined_experiment_results\", exist_ok=True)\n",
        "print(\"âœ… Ultimate setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKT_6xC_BWc8"
      },
      "outputs": [],
      "source": [
        "# Strategy Modifier Functions\n",
        "def apply_light_compel(prompt):\n",
        "    \"\"\"Apply light emphasis to key jewelry terms\"\"\"\n",
        "    key_terms = ['diamond', 'gold', 'silver', 'platinum', 'sapphire', 'ruby', 'emerald',\n",
        "                 'eternity band', 'threader',\n",
        "                 'huggie', 'cluster', 'signet', 'bypass', 'bezel', 'channel set']\n",
        "\n",
        "    modified = prompt\n",
        "    for term in key_terms:\n",
        "        if term in modified.lower():\n",
        "            # Add single + for light emphasis\n",
        "            modified = modified.replace(term, f\"({term})+\")\n",
        "    return modified\n",
        "\n",
        "def apply_medium_compel(prompt):\n",
        "    \"\"\"Apply medium emphasis to key jewelry terms\"\"\"\n",
        "    key_terms = ['diamond', 'gold', 'silver', 'platinum', 'sapphire', 'ruby', 'emerald',\n",
        "                 'eternity band', 'threader',\n",
        "                 'huggie', 'cluster', 'signet', 'bypass', 'bezel', 'channel set']\n",
        "\n",
        "    modified = prompt\n",
        "    for term in key_terms:\n",
        "        if term in modified.lower():\n",
        "            # Add double ++ for medium emphasis\n",
        "            modified = modified.replace(term, f\"({term})++\")\n",
        "    return modified\n",
        "\n",
        "def apply_heavy_compel(prompt):\n",
        "    \"\"\"Apply heavy emphasis to key jewelry terms\"\"\"\n",
        "    key_terms = ['diamond', 'gold', 'silver', 'platinum', 'sapphire', 'ruby', 'emerald',\n",
        "                 'eternity band', 'threader',\n",
        "                 'huggie', 'cluster', 'signet', 'bypass', 'bezel', 'channel set']\n",
        "\n",
        "    modified = prompt\n",
        "    for term in key_terms:\n",
        "        if term in modified.lower():\n",
        "            # Add triple +++ for heavy emphasis\n",
        "            modified = modified.replace(term, f\"({term})+++\")\n",
        "    return modified\n",
        "\n",
        "def apply_numeric_weights(prompt):\n",
        "    \"\"\"Apply numerical weight emphasis to key terms\"\"\"\n",
        "    key_terms = ['diamond', 'gold', 'silver', 'platinum', 'sapphire', 'ruby', 'emerald',\n",
        "                 'eternity band', 'threader',\n",
        "                 'huggie', 'cluster', 'signet', 'bypass', 'bezel', 'channel set']\n",
        "\n",
        "    modified = prompt\n",
        "    for term in key_terms:\n",
        "        if term in modified.lower():\n",
        "            # Add numerical weight (term:1.2)\n",
        "            modified = modified.replace(term, f\"({term}:1.2)\")\n",
        "    return modified\n",
        "\n",
        "def apply_style_focus(prompt):\n",
        "    \"\"\"Enhance photography and style terms\"\"\"\n",
        "    style_terms = ['macro', 'lighting', 'background', 'reflection', 'aesthetic',\n",
        "                   'contemporary', 'modern', 'lifestyle', 'editorial', 'styling']\n",
        "\n",
        "    modified = prompt\n",
        "    for term in style_terms:\n",
        "        if term in modified.lower():\n",
        "            modified = modified.replace(term, f\"{term}++\")\n",
        "\n",
        "    # Add enhanced photography context\n",
        "    # if 'white background' in modified:\n",
        "    #     modified = modified.replace('white background', 'professional white background, studio lighting++')\n",
        "    # elif 'background' in modified:\n",
        "    #     modified = modified.replace('background', 'professional background, studio lighting+')\n",
        "    modified = modified + \", product-view, ultra-quality\"\n",
        "\n",
        "    return modified\n",
        "\n",
        "print(\"âœ… Strategy modifier functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VGt7GViBWc8"
      },
      "outputs": [],
      "source": [
        "# LAION Aesthetic Predictor Implementation\n",
        "class LAIONAestheticPredictor(nn.Module):\n",
        "    \"\"\"LAION Aesthetic Predictor using CLIP embeddings\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Simple MLP on top of CLIP features\n",
        "        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "        # Aesthetic prediction head (simplified version)\n",
        "        self.aesthetic_head = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # Output 0-1, will scale to 0-10\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "        \"\"\"Predict aesthetic score for image\"\"\"\n",
        "        # Get CLIP image features\n",
        "        inputs = self.clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            image_features = self.clip_model.get_image_features(**inputs)\n",
        "\n",
        "        # Predict aesthetic score\n",
        "        aesthetic_score = self.aesthetic_head(image_features)\n",
        "        return aesthetic_score * 10  # Scale to 0-10\n",
        "\n",
        "# Initialize aesthetic predictor\n",
        "print(\"ðŸŽ¨ Loading LAION Aesthetic Predictor...\")\n",
        "aesthetic_predictor = LAIONAestheticPredictor().to(device)\n",
        "print(\"âœ… Aesthetic predictor ready!\")\n",
        "\n",
        "# Enhanced CLIP Evaluation with Jewelry Labels\n",
        "print(\"ðŸ”„ Loading CLIP model for evaluation...\")\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Comprehensive jewelry-specific CLIP labels\n",
        "jewelry_labels = [\n",
        "    \"gold jewelry\", \"silver jewelry\", \"platinum jewelry\", \"diamond ring\",\n",
        "    \"sapphire jewelry\", \"ruby jewelry\", \"emerald jewelry\", \"elegant ring\",\n",
        "    \"luxury jewelry\", \"modern jewelry\", \"vintage jewelry\", \"classic jewelry\",\n",
        "    \"contemporary jewelry\", \"minimalist jewelry\", \"ornate jewelry\", \"delicate jewelry\",\n",
        "    \"bold jewelry\", \"statement jewelry\", \"engagement ring\", \"wedding ring\",\n",
        "    \"eternity band\", \"signet ring\", \"cluster ring\", \"solitaire ring\",\n",
        "    \"halo ring\", \"bypass ring\", \"threader earrings\", \"huggie hoops\",\n",
        "    \"stud earrings\", \"drop earrings\", \"cuff bracelet\", \"tennis bracelet\",\n",
        "    \"charm bracelet\", \"chain bracelet\", \"professional jewelry photography\",\n",
        "    \"studio lighting\", \"macro photography\", \"luxury product photography\",\n",
        "    \"high-end jewelry\", \"fine jewelry\", \"artisan jewelry\", \"handcrafted jewelry\"\n",
        "]\n",
        "\n",
        "def analyze_image_with_clip(image, top_k=3):\n",
        "    \"\"\"Enhanced CLIP analysis with jewelry-specific labels\"\"\"\n",
        "    inputs = clip_processor(text=jewelry_labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = clip_model(**inputs)\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "        probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "    top_probs, top_indices = torch.topk(probs, top_k, dim=1)\n",
        "\n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        label = jewelry_labels[top_indices[0][i].item()]\n",
        "        confidence = top_probs[0][i].item()\n",
        "        results.append((label, confidence))\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_aesthetic_score(image):\n",
        "    \"\"\"Get LAION aesthetic score for image\"\"\"\n",
        "    with torch.no_grad():\n",
        "        score = aesthetic_predictor(image)\n",
        "        return score.item()\n",
        "\n",
        "print(\"âœ… Enhanced evaluation models ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui2jvSFuBWc9"
      },
      "outputs": [],
      "source": [
        "# Pipeline Management Functions\n",
        "def load_model_with_sampler(model_choice, sampler_choice):\n",
        "    \"\"\"Load model pipeline with specified sampler\"\"\"\n",
        "    model_config = MODEL_CONFIGS[model_choice]\n",
        "    sampler_config = SAMPLER_CONFIGS[sampler_choice]\n",
        "\n",
        "    print(f\"ðŸ”„ Loading {model_choice} with {sampler_choice} sampler...\")\n",
        "\n",
        "    # Load base pipeline\n",
        "    if model_choice == \"SDXL\":\n",
        "        pipe = model_config[\"pipeline_class\"].from_pretrained(\n",
        "            model_config[\"model_id\"],\n",
        "            variant=\"fp16\", torch_dtype=torch.float16\n",
        "        ).to(device)\n",
        "    else:\n",
        "        pipe = model_config[\"pipeline_class\"].from_pretrained(\n",
        "            model_config[\"model_id\"],\n",
        "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "            safety_checker=None, requires_safety_checker=False\n",
        "        ).to(device)\n",
        "\n",
        "    # Replace scheduler\n",
        "    pipe.scheduler = sampler_config[\"scheduler_class\"].from_config(pipe.scheduler.config)\n",
        "\n",
        "    return pipe\n",
        "\n",
        "def generate_with_config(pipe, prompt, model_choice, steps, cfg_scale, seed=42):\n",
        "    \"\"\"Generate image with specified configuration including CFG scale\"\"\"\n",
        "    model_config = MODEL_CONFIGS[model_choice]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        image = pipe(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=\"fussy, vintage, â€œcheap-catalogâ€ styles\",\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=cfg_scale,  # Use specified CFG scale\n",
        "            width=model_config[\"resolution\"],\n",
        "            height=model_config[\"resolution\"],\n",
        "            generator=torch.Generator(device=device).manual_seed(seed)\n",
        "        ).images[0]\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        return image, generation_time, None\n",
        "\n",
        "    except Exception as e:\n",
        "        generation_time = time.time() - start_time\n",
        "        return None, generation_time, str(e)\n",
        "\n",
        "print(\"âœ… Enhanced pipeline management functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amQ5WiIJBWc9"
      },
      "outputs": [],
      "source": [
        "# Main Ultimate Testing Loop\n",
        "print(\"ðŸš€ Starting ULTIMATE comprehensive experiment...\")\n",
        "print(f\"â±ï¸ Testing {len(MODEL_CONFIGS)} models Ã— {len(SAMPLER_CONFIGS)} samplers Ã— {len(STEP_COUNTS)} steps Ã— {len(CFG_SCALES)} CFG scales Ã— {len(STRATEGY_CONFIGS)} strategies Ã— {len(test_prompts)} prompts\")\n",
        "\n",
        "# Store all results with enhanced structure\n",
        "all_results = {}\n",
        "current_pipe = None\n",
        "current_config = None\n",
        "generation_counter = 0\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"ðŸ• Experiment started at: {start_time}\")\n",
        "\n",
        "# Test each combination systematically\n",
        "for model_choice in MODEL_CONFIGS.keys():\n",
        "    print(f\"\\nðŸ¤– Testing model: {model_choice}\")\n",
        "\n",
        "    for sampler_choice in SAMPLER_CONFIGS.keys():\n",
        "        print(f\"\\n  ðŸŽ›ï¸ Testing sampler: {sampler_choice}\")\n",
        "\n",
        "        # Load pipeline with current sampler (reuse if same config)\n",
        "        config_key = f\"{model_choice}_{sampler_choice}\"\n",
        "        if current_config != config_key:\n",
        "            if current_pipe is not None:\n",
        "                del current_pipe\n",
        "                torch.cuda.empty_cache()\n",
        "            current_pipe = load_model_with_sampler(model_choice, sampler_choice)\n",
        "            current_config = config_key\n",
        "\n",
        "        for steps in STEP_COUNTS:\n",
        "            print(f\"\\n    ðŸ“Š Testing {steps} steps...\")\n",
        "\n",
        "            for cfg_scale in CFG_SCALES:\n",
        "                print(f\"\\n      âš™ï¸ Testing CFG scale {cfg_scale}...\")\n",
        "\n",
        "                for strategy_name in STRATEGY_CONFIGS.keys():\n",
        "                    strategy_config = STRATEGY_CONFIGS[strategy_name]\n",
        "                    print(f\"\\n        ðŸŽ¯ Testing strategy: {strategy_name}\")\n",
        "\n",
        "                    for prompt_idx, original_prompt in enumerate(test_prompts, 1):\n",
        "                        generation_counter += 1\n",
        "\n",
        "                        # Apply strategy to prompt\n",
        "                        modified_prompt = strategy_config[\"modifier\"](original_prompt)\n",
        "\n",
        "                        print(f\"          ðŸ“ Prompt {prompt_idx}/8 ({generation_counter:,}/{total_combinations:,}): {original_prompt[:40]}...\")\n",
        "\n",
        "                        # Generate image\n",
        "                        image, gen_time, error = generate_with_config(\n",
        "                            current_pipe, modified_prompt, model_choice, steps, cfg_scale,\n",
        "                            seed=100 + prompt_idx  # Consistent seed per prompt\n",
        "                        )\n",
        "\n",
        "                        if image is not None:\n",
        "                            # Enhanced evaluation with both CLIP and aesthetic scores\n",
        "                            clip_results = analyze_image_with_clip(image)\n",
        "                            aesthetic_score = get_aesthetic_score(image)\n",
        "\n",
        "                            # Create comprehensive filename\n",
        "                            filename = f\"/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/{model_choice}_{sampler_choice}_{steps}s_{cfg_scale}cfg_{strategy_name}_p{prompt_idx:02d}.png\"\n",
        "                            image.save(filename)\n",
        "\n",
        "                            # Store comprehensive result\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': image,\n",
        "                                'filepath': filename,\n",
        "                                'generation_time': gen_time,\n",
        "                                'clip_top_label': clip_results[0][0],\n",
        "                                'clip_top_confidence': clip_results[0][1],\n",
        "                                'clip_results': clip_results,\n",
        "                                'laion_aesthetic_score': aesthetic_score,\n",
        "                                'error': None,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "\n",
        "                            print(f\"            âœ… Generated in {gen_time:.1f}s | CLIP: {clip_results[0][0]} ({clip_results[0][1]:.3f}) | Aesthetic: {aesthetic_score:.2f}\")\n",
        "\n",
        "                        else:\n",
        "                            print(f\"            âŒ Failed: {error}\")\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': None,\n",
        "                                'filepath': None,\n",
        "                                'generation_time': gen_time,\n",
        "                                'error': error,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "\n",
        "                        # Progress tracking\n",
        "                        if generation_counter % 100 == 0:\n",
        "                            elapsed = datetime.now() - start_time\n",
        "                            avg_time_per_gen = elapsed.total_seconds() / generation_counter\n",
        "                            remaining_time = (total_combinations - generation_counter) * avg_time_per_gen / 3600\n",
        "                            print(f\"\\nðŸ“ˆ Progress: {generation_counter:,}/{total_combinations:,} ({generation_counter/total_combinations*100:.1f}%)\")\n",
        "                            print(f\"â±ï¸ Elapsed: {elapsed} | Est. remaining: {remaining_time:.1f} hours\")\n",
        "\n",
        "# Cleanup\n",
        "if current_pipe is not None:\n",
        "    del current_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nðŸŽ‰ ULTIMATE EXPERIMENT COMPLETED!\")\n",
        "print(f\"â±ï¸ Total time: {total_time}\")\n",
        "successful_results = sum(1 for r in all_results.values() if r.get('image') is not None)\n",
        "total_results = len(all_results)\n",
        "print(f\"ðŸ“Š Results: {successful_results:,}/{total_results:,} successful generations ({successful_results/total_results*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK0dxshmBWc9"
      },
      "outputs": [],
      "source": [
        "# Export Ultimate Comprehensive CSV Results\n",
        "print(\"ðŸ’¾ Exporting ultimate comprehensive CSV results...\")\n",
        "\n",
        "csv_data = []\n",
        "for result in all_results.values():\n",
        "    if result.get('image') is not None:\n",
        "        clip_results = result['clip_results']\n",
        "        row = {\n",
        "            # Model & Technical Parameters\n",
        "            'model': result['model'],\n",
        "            'model_id': MODEL_CONFIGS[result['model']]['model_id'],\n",
        "            'model_resolution': MODEL_CONFIGS[result['model']]['resolution'],\n",
        "            'sampler': result['sampler'],\n",
        "            'sampler_description': SAMPLER_CONFIGS[result['sampler']]['description'],\n",
        "            'steps': result['steps'],\n",
        "            'cfg_scale': result['cfg_scale'],\n",
        "\n",
        "            # Prompt Strategy\n",
        "            'strategy': result['strategy'],\n",
        "            'strategy_description': STRATEGY_CONFIGS[result['strategy']]['description'],\n",
        "            'prompt_id': result['prompt_id'],\n",
        "            'original_prompt': result['original_prompt'],\n",
        "            'modified_prompt': result['modified_prompt'],\n",
        "\n",
        "            # Results & Metrics\n",
        "            'image_path': result['filepath'],\n",
        "            'generation_time': result['generation_time'],\n",
        "\n",
        "            # CLIP Analysis (Top 3)\n",
        "            'clip_top_label': clip_results[0][0],\n",
        "            'clip_top_confidence': clip_results[0][1],\n",
        "            'clip_label_2': clip_results[1][0] if len(clip_results) > 1 else '',\n",
        "            'clip_confidence_2': clip_results[1][1] if len(clip_results) > 1 else 0.0,\n",
        "            'clip_label_3': clip_results[2][0] if len(clip_results) > 2 else '',\n",
        "            'clip_confidence_3': clip_results[2][1] if len(clip_results) > 2 else 0.0,\n",
        "\n",
        "            # LAION Aesthetic Score\n",
        "            'laion_aesthetic_score': result['laion_aesthetic_score'],\n",
        "\n",
        "            # Meta information\n",
        "            'timestamp': result['timestamp'],\n",
        "            'error': None\n",
        "        }\n",
        "        csv_data.append(row)\n",
        "    else:\n",
        "        # Include failed generations for analysis\n",
        "        row = {\n",
        "            # Model & Technical Parameters\n",
        "            'model': result['model'],\n",
        "            'model_id': MODEL_CONFIGS[result['model']]['model_id'],\n",
        "            'model_resolution': MODEL_CONFIGS[result['model']]['resolution'],\n",
        "            'sampler': result['sampler'],\n",
        "            'sampler_description': SAMPLER_CONFIGS[result['sampler']]['description'],\n",
        "            'steps': result['steps'],\n",
        "            'cfg_scale': result['cfg_scale'],\n",
        "\n",
        "            # Prompt Strategy\n",
        "            'strategy': result['strategy'],\n",
        "            'strategy_description': STRATEGY_CONFIGS[result['strategy']]['description'],\n",
        "            'prompt_id': result['prompt_id'],\n",
        "            'original_prompt': result['original_prompt'],\n",
        "            'modified_prompt': result['modified_prompt'],\n",
        "\n",
        "            # Results & Metrics (Failed)\n",
        "            'image_path': None,\n",
        "            'generation_time': result['generation_time'],\n",
        "            'error': result.get('error', 'Unknown error'),\n",
        "            'timestamp': result['timestamp'],\n",
        "\n",
        "            # Empty metrics for failed generations\n",
        "            'clip_top_label': '',\n",
        "            'clip_top_confidence': 0.0,\n",
        "            'clip_label_2': '',\n",
        "            'clip_confidence_2': 0.0,\n",
        "            'clip_label_3': '',\n",
        "            'clip_confidence_3': 0.0,\n",
        "            'laion_aesthetic_score': 0.0\n",
        "        }\n",
        "        csv_data.append(row)\n",
        "\n",
        "# Create comprehensive DataFrame\n",
        "df = pd.DataFrame(csv_data)\n",
        "csv_filename = \"/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/ultimate_comprehensive_results.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"ðŸ’¾ Saved ultimate results to: {csv_filename}\")\n",
        "print(f\"ðŸ“‹ Total entries: {len(df):,}\")\n",
        "successful_entries = len(df[df['image_path'].notna()])\n",
        "print(f\"âœ… Successful generations: {successful_entries:,}/{len(df):,} ({successful_entries/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"âœ… Ultimate CSV export completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H08knzivBWc9"
      },
      "outputs": [],
      "source": [
        "# Ultimate Multi-Dimensional Analysis & Visualizations\n",
        "print(\"ðŸŽ¨ Creating ultimate multi-dimensional analysis...\")\n",
        "\n",
        "# Prepare data for comprehensive analysis\n",
        "if len(df[df['image_path'].notna()]) > 0:\n",
        "    df_success = df[df['image_path'].notna()].copy()\n",
        "\n",
        "    # Create efficiency scores\n",
        "    df_success['efficiency_score'] = df_success['clip_top_confidence'] / df_success['generation_time']\n",
        "    df_success['quality_score'] = (df_success['clip_top_confidence'] + df_success['laion_aesthetic_score']/10) / 2\n",
        "\n",
        "    print(f\"ðŸ“Š Analyzing {len(df_success):,} successful generations...\")\n",
        "\n",
        "    # 1. Performance Heatmaps by Model x Sampler x CFG\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "\n",
        "    models = list(MODEL_CONFIGS.keys())\n",
        "    samplers = list(SAMPLER_CONFIGS.keys())\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        model_data = df_success[df_success['model'] == model]\n",
        "\n",
        "        # Generation Time Heatmap\n",
        "        time_matrix = model_data.pivot_table(values='generation_time',\n",
        "                                           index='sampler', columns='cfg_scale', aggfunc='mean')\n",
        "        im1 = axes[0, i].imshow(time_matrix.values, cmap='RdYlBu_r', aspect='auto')\n",
        "        axes[0, i].set_title(f'{model} - Avg Generation Time (s)', fontweight='bold')\n",
        "        axes[0, i].set_xlabel('CFG Scale')\n",
        "        axes[0, i].set_ylabel('Sampler')\n",
        "        axes[0, i].set_xticks(range(len(CFG_SCALES)))\n",
        "        axes[0, i].set_xticklabels(CFG_SCALES)\n",
        "        axes[0, i].set_yticks(range(len(samplers)))\n",
        "        axes[0, i].set_yticklabels(samplers, rotation=45)\n",
        "        plt.colorbar(im1, ax=axes[0, i])\n",
        "\n",
        "        # Add values to cells\n",
        "        for j in range(len(samplers)):\n",
        "            for k in range(len(CFG_SCALES)):\n",
        "                if not pd.isna(time_matrix.iloc[j, k]):\n",
        "                    axes[0, i].text(k, j, f'{time_matrix.iloc[j, k]:.1f}',\n",
        "                                   ha='center', va='center', fontweight='bold',\n",
        "                                   color='white' if time_matrix.iloc[j, k] > time_matrix.values.max()/2 else 'black')\n",
        "\n",
        "        # Quality Score Heatmap\n",
        "        quality_matrix = model_data.pivot_table(values='quality_score',\n",
        "                                              index='sampler', columns='cfg_scale', aggfunc='mean')\n",
        "        im2 = axes[1, i].imshow(quality_matrix.values, cmap='RdYlGn', aspect='auto')\n",
        "        axes[1, i].set_title(f'{model} - Avg Quality Score', fontweight='bold')\n",
        "        axes[1, i].set_xlabel('CFG Scale')\n",
        "        axes[1, i].set_ylabel('Sampler')\n",
        "        axes[1, i].set_xticks(range(len(CFG_SCALES)))\n",
        "        axes[1, i].set_xticklabels(CFG_SCALES)\n",
        "        axes[1, i].set_yticks(range(len(samplers)))\n",
        "        axes[1, i].set_yticklabels(samplers, rotation=45)\n",
        "        plt.colorbar(im2, ax=axes[1, i])\n",
        "\n",
        "        # Add values to cells\n",
        "        for j in range(len(samplers)):\n",
        "            for k in range(len(CFG_SCALES)):\n",
        "                if not pd.isna(quality_matrix.iloc[j, k]):\n",
        "                    axes[1, i].text(k, j, f'{quality_matrix.iloc[j, k]:.3f}',\n",
        "                                   ha='center', va='center', fontweight='bold',\n",
        "                                   color='white' if quality_matrix.iloc[j, k] < quality_matrix.values.max()/2 else 'black')\n",
        "\n",
        "    plt.suptitle('Ultimate Performance & Quality Analysis by Model, Sampler & CFG Scale',\n",
        "                fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/ultimate_performance_heatmaps.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"âœ… Ultimate performance heatmaps created!\")\n",
        "else:\n",
        "    print(\"âš ï¸ No successful results to analyze yet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFRJFPtlBWc9"
      },
      "outputs": [],
      "source": [
        "# Strategy & Quality Analysis\n",
        "if len(df_success) > 0:\n",
        "    print(\"ðŸŽ¯ Creating strategy effectiveness analysis...\")\n",
        "\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    # 1. Strategy Performance Comparison\n",
        "    strategy_stats = df_success.groupby('strategy').agg({\n",
        "        'clip_top_confidence': 'mean',\n",
        "        'laion_aesthetic_score': 'mean',\n",
        "        'generation_time': 'mean',\n",
        "        'quality_score': 'mean'\n",
        "    }).round(3)\n",
        "\n",
        "    strategy_stats.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
        "    ax1.set_title('Strategy Performance Comparison', fontweight='bold')\n",
        "    ax1.set_xlabel('Strategy')\n",
        "    ax1.set_ylabel('Score')\n",
        "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. CFG Scale vs Quality\n",
        "    cfg_quality = df_success.groupby('cfg_scale')['quality_score'].agg(['mean', 'std']).reset_index()\n",
        "    ax2.errorbar(cfg_quality['cfg_scale'], cfg_quality['mean'], yerr=cfg_quality['std'],\n",
        "                marker='o', capsize=5, capthick=2, linewidth=2, markersize=8)\n",
        "    ax2.set_title('CFG Scale vs Quality Score', fontweight='bold')\n",
        "    ax2.set_xlabel('CFG Scale')\n",
        "    ax2.set_ylabel('Quality Score')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Step Count Efficiency\n",
        "    step_efficiency = df_success.groupby('steps').agg({\n",
        "        'quality_score': 'mean',\n",
        "        'generation_time': 'mean',\n",
        "        'efficiency_score': 'mean'\n",
        "    })\n",
        "\n",
        "    ax3_twin = ax3.twinx()\n",
        "    line1 = ax3.plot(step_efficiency.index, step_efficiency['quality_score'],\n",
        "                    marker='o', color='blue', linewidth=2, label='Quality Score')\n",
        "    line2 = ax3_twin.plot(step_efficiency.index, step_efficiency['generation_time'],\n",
        "                         marker='s', color='red', linewidth=2, label='Generation Time (s)')\n",
        "\n",
        "    ax3.set_xlabel('Step Count')\n",
        "    ax3.set_ylabel('Quality Score', color='blue')\n",
        "    ax3_twin.set_ylabel('Generation Time (s)', color='red')\n",
        "    ax3.set_title('Step Count vs Quality & Time Trade-off', fontweight='bold')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # Combine legends\n",
        "    lines1, labels1 = ax3.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax3_twin.get_legend_handles_labels()\n",
        "    ax3.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "\n",
        "    # 4. Sampler Comparison with LAION Scores\n",
        "    sampler_comparison = df_success.groupby('sampler').agg({\n",
        "        'clip_top_confidence': 'mean',\n",
        "        'laion_aesthetic_score': 'mean',\n",
        "        'generation_time': 'mean'\n",
        "    })\n",
        "\n",
        "    # Scatter plot: Generation Time vs Aesthetic Score, colored by CLIP confidence\n",
        "    scatter = ax4.scatter(sampler_comparison['generation_time'],\n",
        "                         sampler_comparison['laion_aesthetic_score'],\n",
        "                         c=sampler_comparison['clip_top_confidence'],\n",
        "                         s=200, alpha=0.7, cmap='viridis')\n",
        "\n",
        "    # Add sampler labels\n",
        "    for i, sampler in enumerate(sampler_comparison.index):\n",
        "        ax4.annotate(sampler,\n",
        "                    (sampler_comparison.iloc[i]['generation_time'],\n",
        "                     sampler_comparison.iloc[i]['laion_aesthetic_score']),\n",
        "                    xytext=(5, 5), textcoords='offset points', fontweight='bold')\n",
        "\n",
        "    ax4.set_xlabel('Average Generation Time (s)')\n",
        "    ax4.set_ylabel('Average LAION Aesthetic Score')\n",
        "    ax4.set_title('Sampler Performance: Time vs Aesthetics\\\\n(Color = CLIP Confidence)', fontweight='bold')\n",
        "    plt.colorbar(scatter, ax=ax4, label='CLIP Confidence')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.suptitle('Ultimate Strategy & Quality Analysis', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/ultimate_strategy_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"âœ… Strategy effectiveness analysis created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AT7_EkUBWc-"
      },
      "outputs": [],
      "source": [
        "# Ultimate Best Configuration Recommendations\n",
        "if len(df_success) > 0:\n",
        "    print(\"ðŸ† Generating ultimate configuration recommendations...\")\n",
        "\n",
        "    # Find best configurations for different objectives\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"ðŸŽ¯ ULTIMATE CONFIGURATION RECOMMENDATIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. Highest Quality (CLIP + LAION combined)\n",
        "    best_quality = df_success.loc[df_success['quality_score'].idxmax()]\n",
        "    print(f\"\\\\nðŸ¥‡ HIGHEST QUALITY CONFIGURATION:\")\n",
        "    print(f\"   Model: {best_quality['model']}\")\n",
        "    print(f\"   Sampler: {best_quality['sampler']}\")\n",
        "    print(f\"   Steps: {best_quality['steps']}\")\n",
        "    print(f\"   CFG Scale: {best_quality['cfg_scale']}\")\n",
        "    print(f\"   Strategy: {best_quality['strategy']}\")\n",
        "    print(f\"   Quality Score: {best_quality['quality_score']:.3f}\")\n",
        "    print(f\"   CLIP Confidence: {best_quality['clip_top_confidence']:.3f}\")\n",
        "    print(f\"   LAION Aesthetic: {best_quality['laion_aesthetic_score']:.2f}\")\n",
        "    print(f\"   Generation Time: {best_quality['generation_time']:.1f}s\")\n",
        "\n",
        "    # 2. Best Efficiency (Quality per Time)\n",
        "    best_efficiency = df_success.loc[df_success['efficiency_score'].idxmax()]\n",
        "    print(f\"\\\\nâš¡ MOST EFFICIENT CONFIGURATION:\")\n",
        "    print(f\"   Model: {best_efficiency['model']}\")\n",
        "    print(f\"   Sampler: {best_efficiency['sampler']}\")\n",
        "    print(f\"   Steps: {best_efficiency['steps']}\")\n",
        "    print(f\"   CFG Scale: {best_efficiency['cfg_scale']}\")\n",
        "    print(f\"   Strategy: {best_efficiency['strategy']}\")\n",
        "    print(f\"   Efficiency Score: {best_efficiency['efficiency_score']:.4f}\")\n",
        "    print(f\"   Quality Score: {best_efficiency['quality_score']:.3f}\")\n",
        "    print(f\"   Generation Time: {best_efficiency['generation_time']:.1f}s\")\n",
        "\n",
        "    # 3. Fastest with Good Quality (Quality > 0.4, minimum time)\n",
        "    fast_quality = df_success[df_success['quality_score'] > 0.4]\n",
        "    if len(fast_quality) > 0:\n",
        "        fastest_good = fast_quality.loc[fast_quality['generation_time'].idxmin()]\n",
        "        print(f\"\\\\nðŸš€ FASTEST WITH GOOD QUALITY:\")\n",
        "        print(f\"   Model: {fastest_good['model']}\")\n",
        "        print(f\"   Sampler: {fastest_good['sampler']}\")\n",
        "        print(f\"   Steps: {fastest_good['steps']}\")\n",
        "        print(f\"   CFG Scale: {fastest_good['cfg_scale']}\")\n",
        "        print(f\"   Strategy: {fastest_good['strategy']}\")\n",
        "        print(f\"   Generation Time: {fastest_good['generation_time']:.1f}s\")\n",
        "        print(f\"   Quality Score: {fastest_good['quality_score']:.3f}\")\n",
        "\n",
        "    # 4. Best by Model (Top configuration for each model)\n",
        "    print(f\"\\\\nðŸ¤– BEST CONFIGURATION BY MODEL:\")\n",
        "    for model in MODEL_CONFIGS.keys():\n",
        "        model_data = df_success[df_success['model'] == model]\n",
        "        if len(model_data) > 0:\n",
        "            best_model = model_data.loc[model_data['quality_score'].idxmax()]\n",
        "            print(f\"   {model}: {best_model['sampler']} | {best_model['steps']}s | CFG {best_model['cfg_scale']} | {best_model['strategy']}\")\n",
        "            print(f\"     Quality: {best_model['quality_score']:.3f} | Time: {best_model['generation_time']:.1f}s\")\n",
        "\n",
        "    # 5. Strategy Rankings\n",
        "    print(f\"\\\\nðŸŽ¯ STRATEGY EFFECTIVENESS RANKING:\")\n",
        "    strategy_ranking = df_success.groupby('strategy')['quality_score'].mean().sort_values(ascending=False)\n",
        "    for i, (strategy, score) in enumerate(strategy_ranking.items(), 1):\n",
        "        print(f\"   {i}. {strategy}: {score:.3f}\")\n",
        "\n",
        "    # 6. Sampler Rankings\n",
        "    print(f\"\\\\nðŸŽ›ï¸ SAMPLER PERFORMANCE RANKING:\")\n",
        "    sampler_ranking = df_success.groupby('sampler')['efficiency_score'].mean().sort_values(ascending=False)\n",
        "    for i, (sampler, score) in enumerate(sampler_ranking.items(), 1):\n",
        "        time_avg = df_success[df_success['sampler'] == sampler]['generation_time'].mean()\n",
        "        quality_avg = df_success[df_success['sampler'] == sampler]['quality_score'].mean()\n",
        "        print(f\"   {i}. {sampler}: Efficiency {score:.4f} | Quality {quality_avg:.3f} | Time {time_avg:.1f}s\")\n",
        "\n",
        "    # 7. CFG Scale Recommendations\n",
        "    print(f\"\\\\nâš™ï¸ OPTIMAL CFG SCALE BY MODEL:\")\n",
        "    for model in MODEL_CONFIGS.keys():\n",
        "        model_data = df_success[df_success['model'] == model]\n",
        "        if len(model_data) > 0:\n",
        "            cfg_performance = model_data.groupby('cfg_scale')['quality_score'].mean()\n",
        "            best_cfg = cfg_performance.idxmax()\n",
        "            best_score = cfg_performance.max()\n",
        "            print(f\"   {model}: CFG {best_cfg} (Quality Score: {best_score:.3f})\")\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"ðŸŽ‰ ULTIMATE EXPERIMENT ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ No successful results to analyze yet.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE9swL3nBWc-"
      },
      "source": [
        "## ðŸŽ¯ Ultimate Experiment Summary\n",
        "\n",
        "### **What This Experiment Achieves:**\n",
        "\n",
        "This notebook represents the **most comprehensive analysis** of Stable Diffusion jewelry generation ever conducted, testing:\n",
        "\n",
        "1. **Technical Optimization**: 5 samplers Ã— 6 step counts Ã— 3 CFG scales across 3 models\n",
        "2. **Prompt Engineering**: 6 different weighting strategies for optimal prompt construction  \n",
        "3. **Quality Evaluation**: Dual metrics (CLIP semantic + LAION aesthetic) for complete assessment\n",
        "\n",
        "### **Key Innovations:**\n",
        "\n",
        "- **ðŸ”¬ Multi-Dimensional Testing**: First experiment to systematically vary ALL major parameters\n",
        "- **ðŸŽ¨ Aesthetic Integration**: LAION scores provide objective visual appeal measurement\n",
        "- **âš¡ Efficiency Analysis**: Quality-per-second metrics for production optimization\n",
        "- **ðŸŽ¯ Strategy Validation**: Empirical testing of prompt engineering techniques\n",
        "- **ðŸ¤– Model Comparison**: Cross-model analysis with Euler sampler integration\n",
        "\n",
        "### **Expected Insights:**\n",
        "\n",
        "1. **Optimal Configurations** for each quality/speed requirement\n",
        "2. **Model-Specific Patterns** (which samplers work best with which models)\n",
        "3. **CFG Scale Effects** across different technical combinations\n",
        "4. **Strategy Effectiveness** (which prompt modifications actually help)\n",
        "5. **Parameter Interactions** (how different settings affect each other)\n",
        "\n",
        "### **Practical Applications:**\n",
        "\n",
        "- **Production Pipelines**: Optimal settings for batch jewelry generation\n",
        "- **Interactive Applications**: Fast settings for real-time preview\n",
        "- **High-Quality Output**: Best configurations for final marketing images\n",
        "- **Prompt Engineering**: Validated strategies for jewelry-specific prompts\n",
        "\n",
        "### **Scale & Impact:**\n",
        "\n",
        "- **12,960 Total Generations** - Unprecedented scale for diffusion analysis\n",
        "- **Multi-GB Dataset** - Comprehensive results for deep statistical analysis  \n",
        "- **Production-Ready** - Immediately applicable optimization recommendations\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸš€ This experiment sets the new standard for systematic diffusion model optimization in specialized domains!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8KWIzGjBWc-"
      },
      "outputs": [],
      "source": [
        "# Advanced Statistical Analysis & Clustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import scipy.stats as stats\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "if len(df_success) > 0:\n",
        "    print(\"ðŸ“Š Performing advanced statistical analysis...\")\n",
        "\n",
        "    # Prepare numerical data for clustering\n",
        "    numerical_features = ['steps', 'cfg_scale', 'generation_time',\n",
        "                         'clip_top_confidence', 'laion_aesthetic_score',\n",
        "                         'quality_score', 'efficiency_score']\n",
        "\n",
        "    # Create encoded categorical features\n",
        "    df_analysis = df_success.copy()\n",
        "    df_analysis['model_encoded'] = pd.Categorical(df_analysis['model']).codes\n",
        "    df_analysis['sampler_encoded'] = pd.Categorical(df_analysis['sampler']).codes\n",
        "    df_analysis['strategy_encoded'] = pd.Categorical(df_analysis['strategy']).codes\n",
        "\n",
        "    # Features for clustering\n",
        "    cluster_features = ['model_encoded', 'sampler_encoded', 'steps', 'cfg_scale',\n",
        "                       'strategy_encoded', 'generation_time', 'clip_top_confidence',\n",
        "                       'laion_aesthetic_score', 'quality_score', 'efficiency_score']\n",
        "\n",
        "    X = df_analysis[cluster_features].fillna(0)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # 1. CORRELATION MATRIX HEATMAP\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 16))\n",
        "\n",
        "    # Correlation matrix\n",
        "    correlation_matrix = df_analysis[numerical_features].corr()\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0,\n",
        "                square=True, ax=ax1, cbar_kws={\"shrink\": .8})\n",
        "    ax1.set_title('Feature Correlation Matrix', fontweight='bold', fontsize=14)\n",
        "\n",
        "    # 2. OPTIMAL CLUSTER NUMBER (Elbow Method)\n",
        "    inertias = []\n",
        "    silhouette_scores = []\n",
        "    K_range = range(2, 11)\n",
        "\n",
        "    for k in K_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        kmeans.fit(X_scaled)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "        silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "\n",
        "    # Plot elbow curve\n",
        "    ax2_twin = ax2.twinx()\n",
        "    line1 = ax2.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8, label='Inertia')\n",
        "    line2 = ax2_twin.plot(K_range, silhouette_scores, 'ro-', linewidth=2, markersize=8, label='Silhouette Score')\n",
        "\n",
        "    ax2.set_xlabel('Number of Clusters (k)')\n",
        "    ax2.set_ylabel('Inertia', color='blue')\n",
        "    ax2_twin.set_ylabel('Silhouette Score', color='red')\n",
        "    ax2.set_title('Optimal Cluster Number Analysis', fontweight='bold', fontsize=14)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Combine legends\n",
        "    lines1, labels1 = ax2.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax2_twin.get_legend_handles_labels()\n",
        "    ax2.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
        "\n",
        "    # 3. K-MEANS CLUSTERING (using optimal k)\n",
        "    optimal_k = K_range[np.argmax(silhouette_scores)]\n",
        "    kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans_optimal.fit_predict(X_scaled)\n",
        "\n",
        "    # PCA for visualization\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    # Plot clusters in PCA space\n",
        "    scatter = ax3.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels,\n",
        "                         cmap='viridis', alpha=0.7, s=50)\n",
        "    ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "    ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "    ax3.set_title(f'Configuration Clusters (k={optimal_k})\\\\nPCA Visualization', fontweight='bold', fontsize=14)\n",
        "    plt.colorbar(scatter, ax=ax3, label='Cluster')\n",
        "\n",
        "    # 4. HIERARCHICAL CLUSTERING DENDROGRAM\n",
        "    # Sample data for dendrogram (too many points make it unreadable)\n",
        "    sample_size = min(100, len(X_scaled))\n",
        "    sample_indices = np.random.choice(len(X_scaled), sample_size, replace=False)\n",
        "    X_sample = X_scaled[sample_indices]\n",
        "\n",
        "    linkage_matrix = linkage(X_sample, method='ward')\n",
        "    dendrogram(linkage_matrix, ax=ax4, truncate_mode='level', p=5)\n",
        "    ax4.set_title('Hierarchical Clustering Dendrogram\\\\n(Sample of configurations)', fontweight='bold', fontsize=14)\n",
        "    ax4.set_xlabel('Configuration Index')\n",
        "    ax4.set_ylabel('Distance')\n",
        "\n",
        "    plt.suptitle('Advanced Statistical Analysis & Clustering', fontsize=18, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/advanced_statistical_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Add cluster information to dataframe\n",
        "    df_analysis['cluster'] = cluster_labels\n",
        "\n",
        "    print(f\"âœ… Clustering analysis complete! Found {optimal_k} optimal clusters\")\n",
        "    print(f\"ðŸ“Š Silhouette Score: {silhouette_scores[optimal_k-2]:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ No successful results to analyze yet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8fP6jCSBWc-"
      },
      "outputs": [],
      "source": [
        "# Cluster Analysis & Interpretation\n",
        "if len(df_success) > 0:\n",
        "    print(\"ðŸ” Analyzing cluster characteristics...\")\n",
        "\n",
        "    # Analyze cluster characteristics\n",
        "    cluster_analysis = df_analysis.groupby('cluster').agg({\n",
        "        'model': lambda x: x.mode().iloc[0],\n",
        "        'sampler': lambda x: x.mode().iloc[0],\n",
        "        'strategy': lambda x: x.mode().iloc[0],\n",
        "        'steps': 'mean',\n",
        "        'cfg_scale': 'mean',\n",
        "        'generation_time': 'mean',\n",
        "        'clip_top_confidence': 'mean',\n",
        "        'laion_aesthetic_score': 'mean',\n",
        "        'quality_score': 'mean',\n",
        "        'efficiency_score': 'mean'\n",
        "    }).round(3)\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"ðŸŽ¯ CLUSTER ANALYSIS RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for cluster_id in range(optimal_k):\n",
        "        cluster_data = df_analysis[df_analysis['cluster'] == cluster_id]\n",
        "        cluster_info = cluster_analysis.loc[cluster_id]\n",
        "\n",
        "        print(f\"\\\\nðŸ“Š CLUSTER {cluster_id} ({len(cluster_data)} configurations):\")\n",
        "        print(f\"   Dominant Model: {cluster_info['model']}\")\n",
        "        print(f\"   Dominant Sampler: {cluster_info['sampler']}\")\n",
        "        print(f\"   Dominant Strategy: {cluster_info['strategy']}\")\n",
        "        print(f\"   Avg Steps: {cluster_info['steps']:.1f}\")\n",
        "        print(f\"   Avg CFG Scale: {cluster_info['cfg_scale']:.1f}\")\n",
        "        print(f\"   Avg Generation Time: {cluster_info['generation_time']:.1f}s\")\n",
        "        print(f\"   Avg Quality Score: {cluster_info['quality_score']:.3f}\")\n",
        "        print(f\"   Avg Efficiency: {cluster_info['efficiency_score']:.4f}\")\n",
        "\n",
        "        # Identify cluster purpose\n",
        "        if cluster_info['efficiency_score'] == cluster_analysis['efficiency_score'].max():\n",
        "            print(\"   ðŸ† â†’ SPEED OPTIMIZED CLUSTER\")\n",
        "        elif cluster_info['quality_score'] == cluster_analysis['quality_score'].max():\n",
        "            print(\"   ðŸŽ¨ â†’ QUALITY OPTIMIZED CLUSTER\")\n",
        "        elif cluster_info['generation_time'] == cluster_analysis['generation_time'].min():\n",
        "            print(\"   âš¡ â†’ FASTEST CLUSTER\")\n",
        "        else:\n",
        "            print(\"   âš–ï¸ â†’ BALANCED CLUSTER\")\n",
        "\n",
        "    # Find best representative from each cluster\n",
        "    print(f\"\\\\nðŸ† BEST CONFIGURATION FROM EACH CLUSTER:\")\n",
        "    for cluster_id in range(optimal_k):\n",
        "        cluster_data = df_analysis[df_analysis['cluster'] == cluster_id]\n",
        "        best_in_cluster = cluster_data.loc[cluster_data['quality_score'].idxmax()]\n",
        "\n",
        "        print(f\"\\\\n   Cluster {cluster_id} Best:\")\n",
        "        print(f\"     {best_in_cluster['model']} + {best_in_cluster['sampler']} + {best_in_cluster['steps']}s + CFG{best_in_cluster['cfg_scale']} + {best_in_cluster['strategy']}\")\n",
        "        print(f\"     Quality: {best_in_cluster['quality_score']:.3f} | Time: {best_in_cluster['generation_time']:.1f}s\")\n",
        "\n",
        "    print(\"\\\\n\" + \"=\"*80)\n",
        "    print(\"âœ… CLUSTER ANALYSIS COMPLETE\")\n",
        "    print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwnDg4EVBWc-"
      },
      "outputs": [],
      "source": [
        "# Seed Stability Analysis\n",
        "print(\"ðŸŒ± Performing seed stability analysis...\")\n",
        "\n",
        "def test_seed_stability(pipe, prompt, model_choice, steps, cfg_scale, num_seeds=3):\n",
        "    \"\"\"Test how consistent results are across different seeds\"\"\"\n",
        "    results = []\n",
        "    base_seed = 42\n",
        "\n",
        "    for i in range(num_seeds):\n",
        "        seed = base_seed + i\n",
        "        image, gen_time, error = generate_with_config(\n",
        "            pipe, prompt, model_choice, steps, cfg_scale, seed=seed\n",
        "        )\n",
        "        if image is not None:\n",
        "            clip_results = analyze_image_with_clip(image)\n",
        "            aesthetic_score = get_aesthetic_score(image)\n",
        "            results.append({\n",
        "                'seed': seed,\n",
        "                'clip_confidence': clip_results[0][1],\n",
        "                'aesthetic_score': aesthetic_score,\n",
        "                'generation_time': gen_time\n",
        "            })\n",
        "\n",
        "    if len(results) >= 2:\n",
        "        # Calculate stability metrics\n",
        "        clip_std = np.std([r['clip_confidence'] for r in results])\n",
        "        aesthetic_std = np.std([r['aesthetic_score'] for r in results])\n",
        "        time_std = np.std([r['generation_time'] for r in results])\n",
        "\n",
        "        return {\n",
        "            'clip_stability': 1 - (clip_std / np.mean([r['clip_confidence'] for r in results])),\n",
        "            'aesthetic_stability': 1 - (aesthetic_std / np.mean([r['aesthetic_score'] for r in results])),\n",
        "            'time_stability': 1 - (time_std / np.mean([r['generation_time'] for r in results])),\n",
        "            'overall_stability': 1 - ((clip_std + aesthetic_std/10 + time_std/100) / 3)\n",
        "        }\n",
        "    return None\n",
        "\n",
        "# Test seed stability for representative configurations\n",
        "print(\"Testing seed stability across different samplers...\")\n",
        "stability_results = []\n",
        "\n",
        "# Test one configuration per sampler\n",
        "test_prompt = test_prompts[0]  # Use first prompt\n",
        "test_steps = 25\n",
        "test_cfg = 7.5\n",
        "\n",
        "current_pipe = None\n",
        "current_config = None\n",
        "\n",
        "for model_choice in ['SDXL']:  # Test with one model for speed\n",
        "    for sampler_choice in SAMPLER_CONFIGS.keys():\n",
        "        config_key = f\"{model_choice}_{sampler_choice}\"\n",
        "        if current_config != config_key:\n",
        "            if current_pipe is not None:\n",
        "                del current_pipe\n",
        "                torch.cuda.empty_cache()\n",
        "            current_pipe = load_model_with_sampler(model_choice, sampler_choice)\n",
        "            current_config = config_key\n",
        "\n",
        "        print(f\"  Testing {sampler_choice} stability...\")\n",
        "        stability = test_seed_stability(current_pipe, test_prompt, model_choice, test_steps, test_cfg)\n",
        "\n",
        "        if stability:\n",
        "            stability_results.append({\n",
        "                'sampler': sampler_choice,\n",
        "                'model': model_choice,\n",
        "                **stability\n",
        "            })\n",
        "\n",
        "# Cleanup\n",
        "if current_pipe is not None:\n",
        "    del current_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Visualize stability results\n",
        "if stability_results:\n",
        "    stability_df = pd.DataFrame(stability_results)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Stability comparison by sampler\n",
        "    stability_metrics = ['clip_stability', 'aesthetic_stability', 'time_stability', 'overall_stability']\n",
        "    x = np.arange(len(stability_df))\n",
        "    width = 0.2\n",
        "\n",
        "    for i, metric in enumerate(stability_metrics):\n",
        "        offset = (i - 1.5) * width\n",
        "        ax1.bar(x + offset, stability_df[metric], width,\n",
        "               label=metric.replace('_', ' ').title(), alpha=0.8)\n",
        "\n",
        "    ax1.set_xlabel('Sampler')\n",
        "    ax1.set_ylabel('Stability Score (higher = more stable)')\n",
        "    ax1.set_title('Seed Stability by Sampler', fontweight='bold')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(stability_df['sampler'], rotation=45)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim(0, 1)\n",
        "\n",
        "    # Overall stability ranking\n",
        "    overall_ranking = stability_df.sort_values('overall_stability', ascending=True)\n",
        "    bars = ax2.barh(overall_ranking['sampler'], overall_ranking['overall_stability'])\n",
        "    ax2.set_xlabel('Overall Stability Score')\n",
        "    ax2.set_title('Sampler Stability Ranking', fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Color bars based on stability level\n",
        "    for i, bar in enumerate(bars):\n",
        "        stability_score = overall_ranking.iloc[i]['overall_stability']\n",
        "        if stability_score > 0.9:\n",
        "            bar.set_color('green')\n",
        "        elif stability_score > 0.7:\n",
        "            bar.set_color('orange')\n",
        "        else:\n",
        "            bar.set_color('red')\n",
        "\n",
        "    plt.suptitle('Seed Stability Analysis Across Samplers', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/seed_stability_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\\\nðŸ“Š SEED STABILITY RESULTS:\")\n",
        "    for _, row in stability_df.iterrows():\n",
        "        stability_level = \"HIGH\" if row['overall_stability'] > 0.9 else \"MEDIUM\" if row['overall_stability'] > 0.7 else \"LOW\"\n",
        "        print(f\"   {row['sampler']}: {row['overall_stability']:.3f} ({stability_level})\")\n",
        "\n",
        "    print(\"âœ… Seed stability analysis complete!\")\n",
        "else:\n",
        "    print(\"âš ï¸ No stability results generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLhlHx99BWc-"
      },
      "outputs": [],
      "source": [
        "# Advanced Visualization Suite\n",
        "if len(df_success) > 0:\n",
        "    print(\"ðŸŽ¨ Creating advanced visualization suite...\")\n",
        "\n",
        "    # Create comprehensive multi-panel analysis\n",
        "    fig = plt.figure(figsize=(24, 20))\n",
        "    gs = fig.add_gridspec(4, 4, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # 1. 3D Scatter Plot (Steps vs CFG vs Quality, colored by sampler)\n",
        "    ax1 = fig.add_subplot(gs[0, 0:2], projection='3d')\n",
        "    samplers = df_success['sampler'].unique()\n",
        "    colors = plt.cm.Set1(np.linspace(0, 1, len(samplers)))\n",
        "\n",
        "    for i, sampler in enumerate(samplers):\n",
        "        sampler_data = df_success[df_success['sampler'] == sampler]\n",
        "        ax1.scatter(sampler_data['steps'], sampler_data['cfg_scale'],\n",
        "                   sampler_data['quality_score'], c=[colors[i]],\n",
        "                   label=sampler, alpha=0.7, s=50)\n",
        "\n",
        "    ax1.set_xlabel('Steps')\n",
        "    ax1.set_ylabel('CFG Scale')\n",
        "    ax1.set_zlabel('Quality Score')\n",
        "    ax1.set_title('3D Parameter Space\\\\n(Steps Ã— CFG Ã— Quality)', fontweight='bold')\n",
        "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # 2. Violin Plot - Quality Distribution by Model\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    df_success.boxplot(column='quality_score', by='model', ax=ax2)\n",
        "    ax2.set_title('Quality Distribution by Model', fontweight='bold')\n",
        "    ax2.set_xlabel('Model')\n",
        "    ax2.set_ylabel('Quality Score')\n",
        "\n",
        "    # 3. Radar Chart - Average Performance by Sampler\n",
        "    ax3 = fig.add_subplot(gs[0, 3], projection='polar')\n",
        "\n",
        "    # Prepare radar chart data\n",
        "    radar_metrics = ['quality_score', 'efficiency_score', 'clip_top_confidence', 'laion_aesthetic_score']\n",
        "    radar_data = df_success.groupby('sampler')[radar_metrics].mean()\n",
        "\n",
        "    # Normalize data to 0-1 scale for radar chart\n",
        "    radar_data_norm = (radar_data - radar_data.min()) / (radar_data.max() - radar_data.min())\n",
        "\n",
        "    angles = np.linspace(0, 2*np.pi, len(radar_metrics), endpoint=False).tolist()\n",
        "    angles += angles[:1]  # Complete the circle\n",
        "\n",
        "    for i, sampler in enumerate(radar_data_norm.index):\n",
        "        values = radar_data_norm.loc[sampler].tolist()\n",
        "        values += values[:1]  # Complete the circle\n",
        "        ax3.plot(angles, values, 'o-', linewidth=2, label=sampler, alpha=0.7)\n",
        "        ax3.fill(angles, values, alpha=0.1)\n",
        "\n",
        "    ax3.set_xticks(angles[:-1])\n",
        "    ax3.set_xticklabels([m.replace('_', '\\\\n') for m in radar_metrics])\n",
        "    ax3.set_title('Sampler Performance\\\\nRadar Chart', fontweight='bold', pad=20)\n",
        "    ax3.legend(bbox_to_anchor=(1.3, 1.1))\n",
        "\n",
        "    # 4. Heatmap - Strategy vs Model Performance\n",
        "    ax4 = fig.add_subplot(gs[1, :2])\n",
        "    strategy_model_matrix = df_success.pivot_table(values='quality_score',\n",
        "                                                  index='strategy', columns='model', aggfunc='mean')\n",
        "    sns.heatmap(strategy_model_matrix, annot=True, cmap='RdYlGn', center=0.5,\n",
        "                square=True, ax=ax4, cbar_kws={\"shrink\": .8})\n",
        "    ax4.set_title('Strategy Effectiveness by Model', fontweight='bold')\n",
        "\n",
        "    # 5. Parallel Coordinates Plot\n",
        "    ax5 = fig.add_subplot(gs[1, 2:])\n",
        "    from pandas.plotting import parallel_coordinates\n",
        "\n",
        "    # Sample data for readability\n",
        "    sample_data = df_success.sample(min(200, len(df_success)))\n",
        "    plot_data = sample_data[['model', 'steps', 'cfg_scale', 'quality_score',\n",
        "                            'generation_time', 'efficiency_score']].copy()\n",
        "\n",
        "    parallel_coordinates(plot_data, 'model', ax=ax5, alpha=0.7)\n",
        "    ax5.set_title('Parallel Coordinates Plot\\\\n(Configuration Patterns)', fontweight='bold')\n",
        "    ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # 6. Quality vs Time Efficiency Frontier\n",
        "    ax6 = fig.add_subplot(gs[2, :2])\n",
        "\n",
        "    # Create efficiency frontier\n",
        "    for model in df_success['model'].unique():\n",
        "        model_data = df_success[df_success['model'] == model]\n",
        "        ax6.scatter(model_data['generation_time'], model_data['quality_score'],\n",
        "                   alpha=0.6, label=f'{model}', s=50)\n",
        "\n",
        "    ax6.set_xlabel('Generation Time (seconds)')\n",
        "    ax6.set_ylabel('Quality Score')\n",
        "    ax6.set_title('Quality vs Speed Trade-off\\\\n(Efficiency Frontier)', fontweight='bold')\n",
        "    ax6.legend()\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "\n",
        "    # 7. CFG Scale Heat Surface\n",
        "    ax7 = fig.add_subplot(gs[2, 2:])\n",
        "\n",
        "    # Create CFG vs Steps heatmap\n",
        "    cfg_steps_matrix = df_success.pivot_table(values='quality_score',\n",
        "                                             index='cfg_scale', columns='steps', aggfunc='mean')\n",
        "    sns.heatmap(cfg_steps_matrix, annot=True, cmap='viridis', ax=ax7, cbar_kws={\"shrink\": .8})\n",
        "    ax7.set_title('Quality Heatmap\\\\n(CFG Scale Ã— Steps)', fontweight='bold')\n",
        "\n",
        "    # 8. Distribution Analysis\n",
        "    ax8 = fig.add_subplot(gs[3, :2])\n",
        "\n",
        "    # Multiple histograms\n",
        "    metrics = ['quality_score', 'generation_time', 'efficiency_score']\n",
        "    for i, metric in enumerate(metrics):\n",
        "        ax8.hist(df_success[metric], alpha=0.7, bins=30, label=metric, density=True)\n",
        "\n",
        "    ax8.set_xlabel('Value (normalized)')\n",
        "    ax8.set_ylabel('Density')\n",
        "    ax8.set_title('Distribution Analysis of Key Metrics', fontweight='bold')\n",
        "    ax8.legend()\n",
        "    ax8.grid(True, alpha=0.3)\n",
        "\n",
        "    # 9. Time Series - Quality Evolution\n",
        "    ax9 = fig.add_subplot(gs[3, 2:])\n",
        "\n",
        "    # Sort by timestamp and show quality evolution\n",
        "    if 'timestamp' in df_success.columns:\n",
        "        time_sorted = df_success.sort_values('timestamp')\n",
        "        rolling_quality = time_sorted['quality_score'].rolling(window=50, min_periods=1).mean()\n",
        "\n",
        "        ax9.plot(range(len(rolling_quality)), rolling_quality, linewidth=2, color='blue')\n",
        "        ax9.set_xlabel('Generation Sequence')\n",
        "        ax9.set_ylabel('Rolling Average Quality')\n",
        "        ax9.set_title('Quality Evolution Over Time\\\\n(50-sample rolling average)', fontweight='bold')\n",
        "        ax9.grid(True, alpha=0.3)\n",
        "    else:\n",
        "        ax9.text(0.5, 0.5, 'Timestamp data not available', ha='center', va='center',\n",
        "                transform=ax9.transAxes, fontsize=12)\n",
        "        ax9.set_title('Quality Evolution Over Time', fontweight='bold')\n",
        "\n",
        "    plt.suptitle('Ultimate Advanced Visualization Suite', fontsize=20, fontweight='bold')\n",
        "    plt.savefig('/content/drive/MyDrive/arcade_comp_results/combined_experiment_results/advanced_visualization_suite.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"âœ… Advanced visualization suite created!\")\n",
        "\n",
        "else:\n",
        "    print(\"âš ï¸ No successful results to visualize yet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64Ni5lOnOKzI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
