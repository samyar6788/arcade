{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vpeDs_AmyHA"
      },
      "source": [
        "# 🧪 Compel Experiment - SDXL Prompt Weighting for Jewelry\n",
        "\n",
        "## Testing Compel Library for Enhanced Prompt Adherence\n",
        "\n",
        "This notebook compares baseline SDXL generation vs Compel-enhanced generation for all 8 test prompts.\n",
        "\n",
        "**Key Features:**\n",
        "- Side-by-side image comparison\n",
        "- Jewelry-specific term weighting with `++` syntax\n",
        "- Quantitative evaluation with CLIP similarity\n",
        "- Export results for analysis\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VVkuAh0myHB"
      },
      "source": [
        "## 🔧 Setup & Installation\n",
        "\n",
        "**For Colab Users:**\n",
        "1. Enable GPU: `Runtime` → `Change runtime type` → `GPU`\n",
        "2. Install dependencies below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o5qn3bnhmyHB",
        "outputId": "a02cd08f-4cd0-4337-c42b-2090652f9408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🖥️  Using device: cuda\n",
            "🚀 GPU: NVIDIA A100-SXM4-40GB\n",
            "💾 GPU Memory: 42.5 GB\n",
            "✅ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (uncomment for Colab)\n",
        "# %pip install torch torchvision diffusers transformers accelerate compel pillow matplotlib open-clip-torch\n",
        "\n",
        "# For local development, ensure you have:\n",
        "# pip install compel>=2.0.0 open-clip-torch\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check device and GPU info\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🖥️  Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected - generation will be slow\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(\"compel_results\", exist_ok=True)\n",
        "print(\"✅ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install compel"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GWecgbPWm-co",
        "outputId": "b4a8e791-9475-4f9c-8870-96f4b78a4744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting compel\n",
            "  Downloading compel-2.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: diffusers>=0.11 in /usr/local/lib/python3.11/dist-packages (from compel) (0.34.0)\n",
            "Requirement already satisfied: pyparsing~=3.0 in /usr/local/lib/python3.11/dist-packages (from compel) (3.2.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from compel) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers~=4.25 in /usr/local/lib/python3.11/dist-packages (from compel) (4.55.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (0.34.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (0.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.11->compel) (11.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.25->compel) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.25->compel) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.25->compel) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.25->compel) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->compel) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->compel) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->compel)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->compel)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->compel)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->compel)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->compel)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->compel)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->compel)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->compel)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->compel)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->compel)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->compel)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->compel) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->compel) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers>=0.11->compel) (1.1.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers>=0.11->compel) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->compel) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.11->compel) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.11->compel) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.11->compel) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.11->compel) (2025.8.3)\n",
            "Downloading compel-2.1.1-py3-none-any.whl (31 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, compel\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed compel-2.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "egwAV1dUmyHC",
        "outputId": "2e9e252a-554a-4474-a247-93d4f87e4207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3988728101.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load SDXL pipeline and Compel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcompel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReturnedEmbeddingsType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiffusers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStableDiffusionXLPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/compel/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconditioning_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdiffusers_textual_inversion_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membeddings_provider\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprompt_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/compel/compel.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCLIPTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIPTextModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_attention_control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mACT2FN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_attn_mask_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_create_4d_causal_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prepare_4d_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientCheckpointingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutputWithPooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageClassifierOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformersKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_return_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender_jinja_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/video_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaddingMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_channel_dimension_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_channel_dimension_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from .utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[0;31m# line: 456\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[0;31m# line: 365\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[0;31m# line: 418\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcross_device_ops_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/cross_device_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/cross_device_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/values.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstruct_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpacked_distributed_variable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_while_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtake_while\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_check_name_wrapper\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_filename\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Load SDXL pipeline and Compel\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import torch\n",
        "\n",
        "print(\"🔄 Loading SDXL pipeline...\")\n",
        "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        "    torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "print(\"🔄 Initializing Compel...\")\n",
        "compel = Compel(\n",
        "    tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2],\n",
        "    text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],\n",
        "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "    requires_pooled=[False, True]\n",
        ")\n",
        "\n",
        "print(\"✅ Pipeline and Compel ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBtReKICmyHC"
      },
      "outputs": [],
      "source": [
        "# Define the 8 test prompts and create Compel-enhanced versions\n",
        "test_prompts = [\n",
        "    \"channel-set diamond eternity band, 2 mm width, hammered 18k yellow gold, product-only white background\",\n",
        "    \"14k rose-gold threader earrings, bezel-set round lab diamond ends, lifestyle macro shot, soft natural light\",\n",
        "    \"organic cluster ring with mixed-cut sapphires and diamonds, brushed platinum finish, modern aesthetic\",\n",
        "    \"A solid gold cuff bracelet with blue sapphire, with refined simplicity and intentionally crafted for everyday wear\",\n",
        "    \"modern signet ring, oval face, engraved gothic initial 'M', high-polish sterling silver, subtle reflection\",\n",
        "    \"delicate gold huggie hoops, contemporary styling, isolated on neutral background\",\n",
        "    \"stack of three slim rings: twisted gold, plain platinum, black rhodium pavé, editorial lighting\",\n",
        "    \"bypass ring with stones on it, with refined simplicity and intentionally crafted for everyday wear\"\n",
        "]\n",
        "\n",
        "# Create Compel-enhanced versions with ++ weighting for critical jewelry terms\n",
        "def create_compel_prompt(prompt):\n",
        "    \"\"\"Add ++ weighting to critical jewelry terms for Compel\"\"\"\n",
        "    # Critical jewelry terms to emphasize\n",
        "    critical_terms = {\n",
        "        \"channel-set\": \"channel-set++\",\n",
        "        \"threader\": \"threader++\",\n",
        "        \"bezel-set\": \"bezel-set++\",\n",
        "        \"eternity band\": \"eternity band++\",\n",
        "        \"huggie\": \"huggie++\",\n",
        "        \"bypass\": \"bypass++\",\n",
        "        \"pavé\": \"pavé++\",\n",
        "        \"signet\": \"signet++\",\n",
        "        \"cuff\": \"cuff++\",\n",
        "        \"cluster\": \"cluster++\",\n",
        "    }\n",
        "\n",
        "    enhanced_prompt = prompt\n",
        "    for term, weighted_term in critical_terms.items():\n",
        "        if term in prompt.lower():\n",
        "            # Replace with case-sensitive match\n",
        "            enhanced_prompt = enhanced_prompt.replace(term, weighted_term)\n",
        "    enhanced_prompt = enhanced_prompt + \" (photo realistic)+++\"\n",
        "\n",
        "\n",
        "    return enhanced_prompt\n",
        "\n",
        "# Create enhanced prompts\n",
        "compel_prompts = [create_compel_prompt(prompt) for prompt in test_prompts]\n",
        "\n",
        "# Display comparison\n",
        "print(\"📝 Prompt Comparison:\")\n",
        "for i, (original, enhanced) in enumerate(zip(test_prompts, compel_prompts), 1):\n",
        "    print(f\"\\n{i}. Original: {original}\")\n",
        "    print(f\"   Enhanced: {enhanced}\")\n",
        "\n",
        "# Common negative prompt\n",
        "negative_prompt = \"vintage, ornate, fussy, cheap, low quality, blurry, deformed, ugly\"\n",
        "print(f\"\\n❌ Negative prompt: {negative_prompt}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMSfrxs6myHC"
      },
      "outputs": [],
      "source": [
        "# Generation functions\n",
        "def generate_baseline(prompt, seed=42):\n",
        "    \"\"\"Generate image using standard SDXL pipeline\"\"\"\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    image = pipeline(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=30,\n",
        "        guidance_scale=5.0,\n",
        "        width=1024,\n",
        "        height=1024,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "\n",
        "    return image\n",
        "\n",
        "def generate_with_compel(prompt, seed=42):\n",
        "    \"\"\"Generate image using Compel-enhanced embeddings\"\"\"\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    # Create conditioning with Compel\n",
        "    conditioning, pooled = compel([prompt, negative_prompt])\n",
        "\n",
        "    # Generate image with embeddings\n",
        "    image = pipeline(\n",
        "        prompt_embeds=conditioning[0:1],\n",
        "        pooled_prompt_embeds=pooled[0:1],\n",
        "        negative_prompt_embeds=conditioning[1:2],\n",
        "        negative_pooled_prompt_embeds=pooled[1:2],\n",
        "        num_inference_steps=30,\n",
        "        guidance_scale=5.0,\n",
        "        width=1024,\n",
        "        height=1024,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "\n",
        "    return image\n",
        "\n",
        "def compare_prompts(original_prompt, compel_prompt, prompt_idx, seed=42):\n",
        "    \"\"\"Generate and compare baseline vs Compel images\"\"\"\n",
        "    print(f\"\\n🎨 Generating images for prompt {prompt_idx}...\")\n",
        "    print(f\"Original: {original_prompt[:80]}...\")\n",
        "    print(f\"Compel:   {compel_prompt[:80]}...\")\n",
        "\n",
        "    # Generate both versions\n",
        "    baseline_img = generate_baseline(original_prompt, seed)\n",
        "    compel_img = generate_with_compel(compel_prompt, seed)\n",
        "\n",
        "    # Save images\n",
        "    baseline_img.save(f\"compel_results/prompt_{prompt_idx:02d}_baseline.png\")\n",
        "    compel_img.save(f\"compel_results/prompt_{prompt_idx:02d}_compel.png\")\n",
        "\n",
        "    # Create side-by-side comparison\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "    axes[0].imshow(baseline_img)\n",
        "    axes[0].set_title(f\"Baseline (Prompt {prompt_idx})\", fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(compel_img)\n",
        "    axes[1].set_title(f\"Compel Enhanced (Prompt {prompt_idx})\", fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"compel_results/comparison_{prompt_idx:02d}.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    return baseline_img, compel_img\n",
        "\n",
        "print(\"✅ Generation functions ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBN0rn_ZmyHC"
      },
      "source": [
        "## 🧪 Single Prompt Test\n",
        "\n",
        "Test with one prompt first to verify everything works:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aRi579amyHC"
      },
      "outputs": [],
      "source": [
        "# Test with first prompt\n",
        "test_idx = 1\n",
        "original = test_prompts[0]\n",
        "enhanced = compel_prompts[0]\n",
        "\n",
        "print(f\"🧪 Testing Prompt {test_idx}:\")\n",
        "print(f\"Original: {original}\")\n",
        "print(f\"Enhanced: {enhanced}\")\n",
        "\n",
        "# Generate comparison\n",
        "baseline_img, compel_img = compare_prompts(original, enhanced, test_idx, seed=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC_xSlOQmyHC"
      },
      "source": [
        "## 🎯 Generate All 8 Prompts\n",
        "\n",
        "Run this cell to generate all comparisons (will take some time):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq68BN4HmyHC"
      },
      "outputs": [],
      "source": [
        "# Generate all 8 prompts\n",
        "print(\"🚀 Starting full experiment - generating all 8 prompts...\")\n",
        "print(\"⏱️  This will take approximately 8-16 minutes depending on your GPU\")\n",
        "\n",
        "results = []\n",
        "for i, (original, enhanced) in enumerate(zip(test_prompts, compel_prompts), 1):\n",
        "    try:\n",
        "        baseline_img, compel_img = compare_prompts(original, enhanced, i, seed=42+i)\n",
        "        results.append({\n",
        "            'prompt_id': i,\n",
        "            'original_prompt': original,\n",
        "            'enhanced_prompt': enhanced,\n",
        "            'baseline_image': baseline_img,\n",
        "            'compel_image': compel_img\n",
        "        })\n",
        "        print(f\"✅ Prompt {i}/8 completed\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error with prompt {i}: {e}\")\n",
        "\n",
        "print(f\"\\n🎉 Experiment completed! Generated {len(results)}/8 prompt comparisons\")\n",
        "print(f\"📁 Results saved in: compel_results/\")\n",
        "print(f\"📊 Check the comparison images to evaluate the differences\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRXX0e78myHC"
      },
      "source": [
        "## 📊 Quantitative Evaluation (Optional)\n",
        "\n",
        "Add CLIP similarity scoring to measure prompt adherence quantitatively:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bclLwJ6kmyHC"
      },
      "outputs": [],
      "source": [
        "# CLIP Evaluation (uncomment if open-clip-torch is installed)\n",
        "try:\n",
        "    import open_clip\n",
        "\n",
        "    # Ensure device is defined\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load CLIP model for evaluation\n",
        "    clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
        "    clip_model = clip_model.to(device).eval()\n",
        "    clip_tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
        "\n",
        "    def calculate_clip_similarity(image, text):\n",
        "        \"\"\"Calculate CLIP similarity between image and text\"\"\"\n",
        "        with torch.no_grad():\n",
        "            # Preprocess image and text\n",
        "            image_input = clip_preprocess(image).unsqueeze(0).to(device)\n",
        "            text_input = clip_tokenizer([text])\n",
        "\n",
        "            # Get embeddings\n",
        "            image_features = clip_model.encode_image(image_input)\n",
        "            text_features = clip_model.encode_text(text_input.to(device))\n",
        "\n",
        "            # Normalize and calculate cosine similarity\n",
        "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "            similarity = (image_features @ text_features.T).squeeze().item()\n",
        "\n",
        "            return similarity\n",
        "\n",
        "    # Evaluate results if we have them\n",
        "    if 'results' in locals() and results:\n",
        "        print(\"📊 CLIP Similarity Evaluation:\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        baseline_scores = []\n",
        "        compel_scores = []\n",
        "\n",
        "        for result in results:\n",
        "            prompt_id = result['prompt_id']\n",
        "            original_prompt = result['original_prompt']\n",
        "\n",
        "            # Calculate similarities\n",
        "            baseline_sim = calculate_clip_similarity(result['baseline_image'], original_prompt)\n",
        "            compel_sim = calculate_clip_similarity(result['compel_image'], original_prompt)\n",
        "\n",
        "            baseline_scores.append(baseline_sim)\n",
        "            compel_scores.append(compel_sim)\n",
        "\n",
        "            improvement = compel_sim - baseline_sim\n",
        "            print(f\"Prompt {prompt_id:2d}: Baseline={baseline_sim:.3f}, Compel={compel_sim:.3f}, Δ={improvement:+.3f}\")\n",
        "\n",
        "        # Calculate averages\n",
        "        avg_baseline = sum(baseline_scores) / len(baseline_scores)\n",
        "        avg_compel = sum(compel_scores) / len(compel_scores)\n",
        "        avg_improvement = avg_compel - avg_baseline\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"📈 Average Scores:\")\n",
        "        print(f\"   Baseline:    {avg_baseline:.3f}\")\n",
        "        print(f\"   Compel:      {avg_compel:.3f}\")\n",
        "        print(f\"   Improvement: {avg_improvement:+.3f} ({avg_improvement/avg_baseline*100:+.1f}%)\")\n",
        "\n",
        "        if avg_improvement > 0:\n",
        "            print(\"🎉 Compel shows improvement in prompt adherence!\")\n",
        "        else:\n",
        "            print(\"📝 Baseline performs better - consider adjusting weighting strategy\")\n",
        "\n",
        "    print(\"✅ CLIP evaluation available\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"⚠️  open-clip-torch not installed - skipping quantitative evaluation\")\n",
        "    print(\"   Install with: pip install open-clip-torch\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error in CLIP evaluation: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYyIzz9hmyHD"
      },
      "source": [
        "## 📊 Export Prompt Comparison CSV\n",
        "\n",
        "Generate a CSV file with original vs Compel-enhanced prompts for analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAmrvqx6myHD"
      },
      "outputs": [],
      "source": [
        "# Export prompt comparison to CSV\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def export_prompt_comparison():\n",
        "    \"\"\"Export original and Compel-enhanced prompts to CSV\"\"\"\n",
        "\n",
        "    # Create comparison data\n",
        "    comparison_data = []\n",
        "    for i, (original, enhanced) in enumerate(zip(test_prompts, compel_prompts), 1):\n",
        "        comparison_data.append({\n",
        "            'prompt_id': i,\n",
        "            'original_prompt': original,\n",
        "            'compel_enhanced_prompt': enhanced,\n",
        "            'changes': ', '.join([term + '++' for term in ['channel-set', 'threader', 'bezel-set', 'eternity band', 'huggie', 'bypass', 'pavé', 'signet', 'cuff', 'cluster', 'diamond', 'sapphire', 'gold', 'platinum'] if term in original.lower()])\n",
        "        })\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_filename = \"compel_results/prompt_comparison.csv\"\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "\n",
        "    # Display the comparison\n",
        "    print(\"📊 Prompt Comparison Table:\")\n",
        "    print(\"=\" * 100)\n",
        "    for _, row in df.iterrows():\n",
        "        print(f\"\\n🔢 Prompt {row['prompt_id']}:\")\n",
        "        print(f\"   Original: {row['original_prompt'][:80]}...\")\n",
        "        print(f\"   Enhanced: {row['compel_enhanced_prompt'][:80]}...\")\n",
        "        if row['changes']:\n",
        "            print(f\"   Weighted: {row['changes']}\")\n",
        "\n",
        "    print(f\"\\n💾 CSV saved to: {csv_filename}\")\n",
        "    print(f\"📋 Total prompts: {len(df)}\")\n",
        "\n",
        "    # Show summary of changes\n",
        "    all_changes = []\n",
        "    for _, row in df.iterrows():\n",
        "        if row['changes']:\n",
        "            all_changes.extend(row['changes'].split(', '))\n",
        "\n",
        "    from collections import Counter\n",
        "    change_counts = Counter(all_changes)\n",
        "\n",
        "    print(f\"\\n📈 Most weighted terms:\")\n",
        "    for term, count in change_counts.most_common(5):\n",
        "        print(f\"   {term}: {count} times\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Run the export\n",
        "prompt_df = export_prompt_comparison()\n",
        "\n",
        "# Display first few rows\n",
        "print(f\"\\n📋 Preview of CSV data:\")\n",
        "print(prompt_df[['prompt_id', 'original_prompt', 'compel_enhanced_prompt']].head(3).to_string(max_colwidth=50))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJWVkNsQmyHD"
      },
      "source": [
        "## 📋 Results Summary\n",
        "\n",
        "The notebook generates:\n",
        "\n",
        "### 📁 **Files Created:**\n",
        "- `compel_results/prompt_XX_baseline.png` - Baseline generations\n",
        "- `compel_results/prompt_XX_compel.png` - Compel-enhanced generations  \n",
        "- `compel_results/comparison_XX.png` - Side-by-side comparisons\n",
        "- `compel_results/prompt_comparison.csv` - CSV with original vs enhanced prompts\n",
        "\n",
        "### 🔍 **What to Look For:**\n",
        "\n",
        "**Visual Differences:**\n",
        "- **Prompt adherence**: Does Compel better capture specific jewelry terms?\n",
        "- **Detail quality**: Are jewelry features more defined/accurate?\n",
        "- **Style consistency**: Modern vs vintage aesthetic differences\n",
        "\n",
        "**Quantitative Metrics:**\n",
        "- **CLIP similarity scores**: Higher = better prompt adherence\n",
        "- **Average improvement**: Overall lift from Compel weighting\n",
        "\n",
        "### 🎯 **Next Steps:**\n",
        "1. **Visual inspection**: Compare side-by-side images\n",
        "2. **Quantitative analysis**: Review CLIP similarity scores\n",
        "3. **CSV analysis**: Use the exported CSV for systematic comparison\n",
        "4. **Fine-tuning**: Adjust `++` weights based on results\n",
        "5. **Integration**: If successful, integrate into main pipeline\n",
        "\n",
        "---\n",
        "\n",
        "**💡 Pro Tip:** Try different weighting levels (`+`, `++`, `+++`) for terms that show the most improvement!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qoo6tpOYmyHD"
      },
      "source": [
        "## 🔬 Compare SDXL vs SD 1.5 with and without Compel\n",
        "\n",
        "This section loads each model (SDXL and SD 1.5), generates baseline and Compel-enhanced images for all 8 prompts at 768×768, and optionally computes CLIP adherence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u-QpHcPmyHD"
      },
      "outputs": [],
      "source": [
        "# Utilities for loading pipelines with/without Compel\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "class ModelVariant:\n",
        "    SD15 = \"runwayml/stable-diffusion-v1-5\"\n",
        "    SDXL = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "def load_pipeline(model_id: str, device: str = device):\n",
        "    if \"xl\" in model_id.lower():\n",
        "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "            model_id, variant=\"fp16\", use_safetensors=True, torch_dtype=torch.float16\n",
        "        ).to(device)\n",
        "        compel_inst = Compel(\n",
        "            tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
        "            text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "            returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "            requires_pooled=[False, True],\n",
        "        )\n",
        "        return pipe, compel_inst\n",
        "    else:\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            model_id, torch_dtype=torch.float16 if device==\"cuda\" else torch.float32\n",
        "        ).to(device)\n",
        "        # For SD1.5 we can still use Compel with single tokenizer/encoder\n",
        "        compel_inst = Compel(\n",
        "            tokenizer=pipe.tokenizer,\n",
        "            text_encoder=pipe.text_encoder,\n",
        "            returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "            requires_pooled=False,\n",
        "        )\n",
        "        return pipe, compel_inst\n",
        "\n",
        "\n",
        "def generate_pair(pipe, compel_inst, base_prompt: str, neg_prompt: str, w: int=768, h: int=768, steps: int=30, cfg: float=7.5, seed: int=42):\n",
        "    gen = torch.Generator(device=device).manual_seed(seed)\n",
        "    # Baseline\n",
        "    img_base = pipe(\n",
        "        prompt=base_prompt,\n",
        "        negative_prompt=neg_prompt,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=cfg,\n",
        "        width=w, height=h,\n",
        "        generator=gen,\n",
        "    ).images[0]\n",
        "    # Compel\n",
        "    if isinstance(compel_inst.tokenizer, list):\n",
        "        cond, pooled = compel_inst([base_prompt, neg_prompt])\n",
        "        img_compel = pipe(\n",
        "            prompt_embeds=cond[0:1], pooled_prompt_embeds=pooled[0:1],\n",
        "            negative_prompt_embeds=cond[1:2], negative_pooled_prompt_embeds=pooled[1:2],\n",
        "            num_inference_steps=steps, guidance_scale=(5.0 if \"xl\" in pipe.__class__.__name__.lower() else cfg),\n",
        "            width=w, height=h, generator=gen,\n",
        "        ).images[0]\n",
        "    else:\n",
        "        cond = compel_inst.build_conditioning_tensor(base_prompt)\n",
        "        ncond = compel_inst.build_conditioning_tensor(neg_prompt)\n",
        "        img_compel = pipe(\n",
        "            prompt_embeds=cond, negative_prompt_embeds=ncond,\n",
        "            num_inference_steps=steps, guidance_scale=cfg,\n",
        "            width=w, height=h, generator=gen,\n",
        "        ).images[0]\n",
        "    return img_base, img_compel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOCLrvpGmyHD"
      },
      "outputs": [],
      "source": [
        "# Run comparison for SDXL and SD 1.5\n",
        "models = [ModelVariant.SDXL, ModelVariant.SD15]\n",
        "results_compare = {}\n",
        "\n",
        "for mid in models:\n",
        "    print(f\"\\n🧪 Testing model: {mid}\")\n",
        "    pipe, compel_inst = load_pipeline(mid)\n",
        "    model_key = 'SDXL' if 'xl' in mid.lower() else 'SD15'\n",
        "    results_compare[model_key] = []\n",
        "\n",
        "    for i, (orig, enh) in enumerate(zip(test_prompts, compel_prompts), 1):\n",
        "        try:\n",
        "            img_b, img_c = generate_pair(pipe, compel_inst, orig, negative_prompt, w=768, h=768, steps=28, cfg=(5.0 if model_key=='SDXL' else 7.5), seed=100+i)\n",
        "            # Save\n",
        "            base_path = f\"compel_results/{model_key.lower()}\"\n",
        "            os.makedirs(base_path, exist_ok=True)\n",
        "            img_b.save(f\"{base_path}/p{i:02d}_baseline.png\")\n",
        "            img_c.save(f\"{base_path}/p{i:02d}_compel.png\")\n",
        "            results_compare[model_key].append((img_b, img_c, orig))\n",
        "            print(f\"  ✅ Prompt {i} done\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Prompt {i} failed: {e}\")\n",
        "\n",
        "print(\"\\n✅ Finished generating for both models.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ4JQiQ2myHD"
      },
      "outputs": [],
      "source": [
        "# Optional: CLIP evaluation across models if open_clip is available\n",
        "try:\n",
        "    import open_clip\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
        "    clip_model = clip_model.to(device).eval()\n",
        "    clip_tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
        "\n",
        "    def clip_score(image, text):\n",
        "        with torch.no_grad():\n",
        "            image_in = clip_preprocess(image).unsqueeze(0).to(device)\n",
        "            text_in = clip_tokenizer([text]).to(device)\n",
        "            im = clip_model.encode_image(image_in)\n",
        "            tx = clip_model.encode_text(text_in)\n",
        "            im = im / im.norm(dim=-1, keepdim=True)\n",
        "            tx = tx / tx.norm(dim=-1, keepdim=True)\n",
        "            return float((im @ tx.T).squeeze().item())\n",
        "\n",
        "    for model_key, rows in results_compare.items():\n",
        "        print(f\"\\n📊 CLIP Adherence for {model_key}\")\n",
        "        base_scores, compel_scores = [], []\n",
        "        for (img_b, img_c, text) in rows:\n",
        "            base_scores.append(clip_score(img_b, text))\n",
        "            compel_scores.append(clip_score(img_c, text))\n",
        "        if base_scores and compel_scores:\n",
        "            mb, mc = sum(base_scores)/len(base_scores), sum(compel_scores)/len(compel_scores)\n",
        "            print(f\"   Baseline: {mb:.3f}  Compel: {mc:.3f}  Δ={mc-mb:+.3f}\")\n",
        "        else:\n",
        "            print(\"   No results to score.\")\n",
        "    print(\"\\n✅ Cross-model CLIP evaluation complete\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Skipping cross-model CLIP evaluation: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}