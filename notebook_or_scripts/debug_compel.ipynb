{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç Debug Compel: Why Are Results Poor?\n",
        "\n",
        "## Hypothesis Testing\n",
        "\n",
        "Based on the poor results, let's test different weighting levels and strategies:\n",
        "\n",
        "1. **Test lighter weighting**: `+` instead of `++`\n",
        "2. **Test specific terms**: Only weight the most important terms\n",
        "3. **Test different models**: See if it's model-specific\n",
        "4. **Visual inspection**: Look at actual images to see what's wrong\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import torch\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Load SDXL\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\", \n",
        "    variant=\"fp16\", torch_dtype=torch.float16\n",
        ").to(device)\n",
        "\n",
        "compel = Compel(\n",
        "    tokenizer=[pipe.tokenizer, pipe.tokenizer_2],\n",
        "    text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "    returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "    requires_pooled=[False, True],\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Setup complete\")\n",
        "\n",
        "# Test prompt\n",
        "test_prompt = \"modern signet ring, oval face, engraved gothic initial 'M', high-polish sterling silver\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different weighting strategies\n",
        "strategies = {\n",
        "    \"baseline\": test_prompt,\n",
        "    \"light_weight\": \"modern signet+ ring, oval face, engraved+ gothic+ initial+ 'M'+\",\n",
        "    \"medium_weight\": \"modern signet++ ring, oval face, engraved++ gothic++ initial++ 'M'++\", \n",
        "    \"heavy_weight\": \"modern signet+++ ring, oval face, engraved+++ gothic+++ initial+++ 'M'+++\",\n",
        "    \"selective\": \"modern (signet)1.2 ring, oval face, (engraved)1.3 gothic (initial)1.2 'M'\"\n",
        "}\n",
        "\n",
        "print(\"üß™ Testing different weighting strategies:\")\n",
        "for name, prompt in strategies.items():\n",
        "    print(f\"  {name}: {prompt}\")\n",
        "\n",
        "# Generate and compare\n",
        "results = {}\n",
        "for name, prompt in strategies.items():\n",
        "    print(f\"\\nüé® Generating: {name}\")\n",
        "    \n",
        "    if name == \"baseline\":\n",
        "        # Standard generation\n",
        "        image = pipe(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=20,\n",
        "            guidance_scale=5.0,\n",
        "            width=512, height=512,\n",
        "            generator=torch.Generator(device=device).manual_seed(42)\n",
        "        ).images[0]\n",
        "    else:\n",
        "        # Compel generation\n",
        "        try:\n",
        "            cond, pooled = compel([prompt])\n",
        "            image = pipe(\n",
        "                prompt_embeds=cond,\n",
        "                pooled_prompt_embeds=pooled,\n",
        "                num_inference_steps=20,\n",
        "                guidance_scale=5.0,\n",
        "                width=512, height=512,\n",
        "                generator=torch.Generator(device=device).manual_seed(42)\n",
        "            ).images[0]\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Failed: {e}\")\n",
        "            continue\n",
        "    \n",
        "    results[name] = image\n",
        "    print(f\"  ‚úÖ Generated: {name}\")\n",
        "\n",
        "print(f\"\\nüéâ Generated {len(results)} test images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visual comparison\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, image) in enumerate(results.items()):\n",
        "    if i < len(axes):\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"{name}\", fontweight='bold')\n",
        "        axes[i].axis('off')\n",
        "\n",
        "# Hide unused subplots\n",
        "for i in range(len(results), len(axes)):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"compel_debug_comparison.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Key Questions:\")\n",
        "print(\"1. Do the Compel images look worse than baseline?\")\n",
        "print(\"2. Is the 'M' more visible in any version?\") \n",
        "print(\"3. Are there artifacts or quality issues?\")\n",
        "print(\"4. Which weighting level works best?\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
