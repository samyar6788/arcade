{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¯ SD 1.5 Prompting Techniques for Jewelry Generation\n",
        "## Based on Machine Learning Mastery Article\n",
        "\n",
        "This notebook implements various prompting techniques from the Machine Learning Mastery article to improve jewelry image generation using **Stable Diffusion 1.5**. Each technique is tested on all 8 Arcade assignment prompts with 6 different seeds.\n",
        "\n",
        "## ðŸŽ¨ Techniques Tested:\n",
        "1. **Baseline Prompts** - Original prompts without enhancement\n",
        "2. **Medium Enhancement** - Adding photography medium specifications  \n",
        "3. **Artistic Style** - Adding artistic style keywords\n",
        "4. **Famous Artists** - Including renowned artist names\n",
        "5. **Website References** - Adding platform names (ArtStation, etc.)\n",
        "6. **Resolution Enhancement** - High-quality descriptors (4K, sharp focus, etc.)\n",
        "7. **Lighting Enhancement** - Professional lighting techniques\n",
        "8. **Color Enhancement** - Specific color guidance\n",
        "9. **Negative Prompts** - What NOT to include\n",
        "10. **Keyword Emphasis** - Using weighting factors\n",
        "\n",
        "## ðŸ“Š Output Format:\n",
        "- **8 rows Ã— 7 columns grid** for each technique\n",
        "- **Row 1-8**: Each jewelry prompt from Arcade assignment\n",
        "- **Column 1**: Prompt text\n",
        "- **Columns 2-7**: 6 generated images with different seeds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "# Set up device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load SD 1.5 pipeline\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False\n",
        ")\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "# Use DPM++ 2M Karras sampler as recommended in article\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "# Enable memory efficient attention\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "# Try to enable xformers if available, fallback gracefully if not\n",
        "try:\n",
        "    if device == \"cuda\":\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "        print(\"âœ… xformers memory optimization enabled\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ xformers not available, using standard attention: {str(e)}\")\n",
        "    # Use alternative memory optimizations\n",
        "    if hasattr(pipe, 'enable_model_cpu_offload'):\n",
        "        pipe.enable_model_cpu_offload()\n",
        "        print(\"âœ… CPU offloading enabled as alternative\")\n",
        "\n",
        "print(\"âœ… SD 1.5 pipeline loaded successfully!\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"sd15_prompting_results\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main Ultimate Testing Loop\n",
        "print(\"ðŸš€ Starting ULTIMATE comprehensive experiment...\")\n",
        "print(f\"â±ï¸ Testing {len(MODEL_CONFIGS)} models Ã— {len(SAMPLER_CONFIGS)} samplers Ã— {len(STEP_COUNTS)} steps Ã— {len(CFG_SCALES)} CFG scales Ã— {len(STRATEGY_CONFIGS)} strategies Ã— {len(test_prompts)} prompts\")\n",
        "\n",
        "# Store all results with enhanced structure\n",
        "all_results = {}\n",
        "current_pipe = None\n",
        "current_config = None\n",
        "generation_counter = 0\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"ðŸ• Experiment started at: {start_time}\")\n",
        "\n",
        "# Test each combination systematically\n",
        "for model_choice in MODEL_CONFIGS.keys():\n",
        "    print(f\"\\nðŸ¤– Testing model: {model_choice}\")\n",
        "    \n",
        "    for sampler_choice in SAMPLER_CONFIGS.keys():\n",
        "        print(f\"\\n  ðŸŽ›ï¸ Testing sampler: {sampler_choice}\")\n",
        "        \n",
        "        # Load pipeline with current sampler (reuse if same config)\n",
        "        config_key = f\"{model_choice}_{sampler_choice}\"\n",
        "        if current_config != config_key:\n",
        "            if current_pipe is not None:\n",
        "                del current_pipe\n",
        "                torch.cuda.empty_cache()\n",
        "            current_pipe = load_model_with_sampler(model_choice, sampler_choice)\n",
        "            current_config = config_key\n",
        "        \n",
        "        for steps in STEP_COUNTS:\n",
        "            print(f\"\\n    ðŸ“Š Testing {steps} steps...\")\n",
        "            \n",
        "            for cfg_scale in CFG_SCALES:\n",
        "                print(f\"\\n      âš™ï¸ Testing CFG scale {cfg_scale}...\")\n",
        "                \n",
        "                for strategy_name in STRATEGY_CONFIGS.keys():\n",
        "                    strategy_config = STRATEGY_CONFIGS[strategy_name]\n",
        "                    print(f\"\\n        ðŸŽ¯ Testing strategy: {strategy_name}\")\n",
        "                    \n",
        "                    for prompt_idx, original_prompt in enumerate(test_prompts, 1):\n",
        "                        generation_counter += 1\n",
        "                        \n",
        "                        # Apply strategy to prompt\n",
        "                        modified_prompt = strategy_config[\"modifier\"](original_prompt)\n",
        "                        \n",
        "                        print(f\"          ðŸ“ Prompt {prompt_idx}/8 ({generation_counter:,}/{total_combinations:,}): {original_prompt[:40]}...\")\n",
        "                        \n",
        "                        # Generate image\n",
        "                        image, gen_time, error = generate_with_config(\n",
        "                            current_pipe, modified_prompt, model_choice, steps, cfg_scale,\n",
        "                            seed=100 + prompt_idx  # Consistent seed per prompt\n",
        "                        )\n",
        "                        \n",
        "                        if image is not None:\n",
        "                            # Enhanced evaluation with both CLIP and aesthetic scores\n",
        "                            clip_results = analyze_image_with_clip(image)\n",
        "                            aesthetic_score = get_aesthetic_score(image)\n",
        "                            \n",
        "                            # Create comprehensive filename\n",
        "                            filename = f\"combined_experiment_results/{model_choice}_{sampler_choice}_{steps}s_{cfg_scale}cfg_{strategy_name}_p{prompt_idx:02d}.png\"\n",
        "                            image.save(filename)\n",
        "                            \n",
        "                            # Store comprehensive result\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': image,\n",
        "                                'filepath': filename,\n",
        "                                'generation_time': gen_time,\n",
        "                                'clip_top_label': clip_results[0][0],\n",
        "                                'clip_top_confidence': clip_results[0][1],\n",
        "                                'clip_results': clip_results,\n",
        "                                'laion_aesthetic_score': aesthetic_score,\n",
        "                                'error': None,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                            \n",
        "                            print(f\"            âœ… Generated in {gen_time:.1f}s | CLIP: {clip_results[0][0]} ({clip_results[0][1]:.3f}) | Aesthetic: {aesthetic_score:.2f}\")\n",
        "                            \n",
        "                        else:\n",
        "                            print(f\"            âŒ Failed: {error}\")\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': None,\n",
        "                                'filepath': None,\n",
        "                                'generation_time': gen_time,\n",
        "                                'error': error,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                        \n",
        "                        # Progress tracking\n",
        "                        if generation_counter % 100 == 0:\n",
        "                            elapsed = datetime.now() - start_time\n",
        "                            avg_time_per_gen = elapsed.total_seconds() / generation_counter\n",
        "                            remaining_time = (total_combinations - generation_counter) * avg_time_per_gen / 3600\n",
        "                            print(f\"\\nðŸ“ˆ Progress: {generation_counter:,}/{total_combinations:,} ({generation_counter/total_combinations*100:.1f}%)\")\n",
        "                            print(f\"â±ï¸ Elapsed: {elapsed} | Est. remaining: {remaining_time:.1f} hours\")\n",
        "\n",
        "# Cleanup\n",
        "if current_pipe is not None:\n",
        "    del current_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nðŸŽ‰ ULTIMATE EXPERIMENT COMPLETED!\")\n",
        "print(f\"â±ï¸ Total time: {total_time}\")\n",
        "successful_results = sum(1 for r in all_results.values() if r.get('image') is not None)\n",
        "total_results = len(all_results)\n",
        "print(f\"ðŸ“Š Results: {successful_results:,}/{total_results:,} successful generations ({successful_results/total_results*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main Ultimate Testing Loop\n",
        "print(\"ðŸš€ Starting ULTIMATE comprehensive experiment...\")\n",
        "print(f\"â±ï¸ Testing {len(MODEL_CONFIGS)} models Ã— {len(SAMPLER_CONFIGS)} samplers Ã— {len(STEP_COUNTS)} steps Ã— {len(CFG_SCALES)} CFG scales Ã— {len(STRATEGY_CONFIGS)} strategies Ã— {len(test_prompts)} prompts\")\n",
        "\n",
        "# Store all results with enhanced structure\n",
        "all_results = {}\n",
        "current_pipe = None\n",
        "current_config = None\n",
        "generation_counter = 0\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"ðŸ• Experiment started at: {start_time}\")\n",
        "\n",
        "# Test each combination systematically\n",
        "for model_choice in MODEL_CONFIGS.keys():\n",
        "    print(f\"\\nðŸ¤– Testing model: {model_choice}\")\n",
        "    \n",
        "    for sampler_choice in SAMPLER_CONFIGS.keys():\n",
        "        print(f\"\\n  ðŸŽ›ï¸ Testing sampler: {sampler_choice}\")\n",
        "        \n",
        "        # Load pipeline with current sampler (reuse if same config)\n",
        "        config_key = f\"{model_choice}_{sampler_choice}\"\n",
        "        if current_config != config_key:\n",
        "            if current_pipe is not None:\n",
        "                del current_pipe\n",
        "                torch.cuda.empty_cache()\n",
        "            current_pipe = load_model_with_sampler(model_choice, sampler_choice)\n",
        "            current_config = config_key\n",
        "        \n",
        "        for steps in STEP_COUNTS:\n",
        "            print(f\"\\n    ðŸ“Š Testing {steps} steps...\")\n",
        "            \n",
        "            for cfg_scale in CFG_SCALES:\n",
        "                print(f\"\\n      âš™ï¸ Testing CFG scale {cfg_scale}...\")\n",
        "                \n",
        "                for strategy_name in STRATEGY_CONFIGS.keys():\n",
        "                    strategy_config = STRATEGY_CONFIGS[strategy_name]\n",
        "                    print(f\"\\n        ðŸŽ¯ Testing strategy: {strategy_name}\")\n",
        "                    \n",
        "                    for prompt_idx, original_prompt in enumerate(test_prompts, 1):\n",
        "                        generation_counter += 1\n",
        "                        \n",
        "                        # Apply strategy to prompt\n",
        "                        modified_prompt = strategy_config[\"modifier\"](original_prompt)\n",
        "                        \n",
        "                        print(f\"          ðŸ“ Prompt {prompt_idx}/8 ({generation_counter:,}/{total_combinations:,}): {original_prompt[:40]}...\")\n",
        "                        \n",
        "                        # Generate image\n",
        "                        image, gen_time, error = generate_with_config(\n",
        "                            current_pipe, modified_prompt, model_choice, steps, cfg_scale,\n",
        "                            seed=100 + prompt_idx  # Consistent seed per prompt\n",
        "                        )\n",
        "                        \n",
        "                        if image is not None:\n",
        "                            # Enhanced evaluation with both CLIP and aesthetic scores\n",
        "                            clip_results = analyze_image_with_clip(image)\n",
        "                            aesthetic_score = get_aesthetic_score(image)\n",
        "                            \n",
        "                            # Create comprehensive filename\n",
        "                            filename = f\"combined_experiment_results/{model_choice}_{sampler_choice}_{steps}s_{cfg_scale}cfg_{strategy_name}_p{prompt_idx:02d}.png\"\n",
        "                            image.save(filename)\n",
        "                            \n",
        "                            # Store comprehensive result\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': image,\n",
        "                                'filepath': filename,\n",
        "                                'generation_time': gen_time,\n",
        "                                'clip_top_label': clip_results[0][0],\n",
        "                                'clip_top_confidence': clip_results[0][1],\n",
        "                                'clip_results': clip_results,\n",
        "                                'laion_aesthetic_score': aesthetic_score,\n",
        "                                'error': None,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                            \n",
        "                            print(f\"            âœ… Generated in {gen_time:.1f}s | CLIP: {clip_results[0][0]} ({clip_results[0][1]:.3f}) | Aesthetic: {aesthetic_score:.2f}\")\n",
        "                            \n",
        "                        else:\n",
        "                            print(f\"            âŒ Failed: {error}\")\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': None,\n",
        "                                'filepath': None,\n",
        "                                'generation_time': gen_time,\n",
        "                                'error': error,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                        \n",
        "                        # Progress tracking\n",
        "                        if generation_counter % 100 == 0:\n",
        "                            elapsed = datetime.now() - start_time\n",
        "                            avg_time_per_gen = elapsed.total_seconds() / generation_counter\n",
        "                            remaining_time = (total_combinations - generation_counter) * avg_time_per_gen / 3600\n",
        "                            print(f\"\\nðŸ“ˆ Progress: {generation_counter:,}/{total_combinations:,} ({generation_counter/total_combinations*100:.1f}%)\")\n",
        "                            print(f\"â±ï¸ Elapsed: {elapsed} | Est. remaining: {remaining_time:.1f} hours\")\n",
        "\n",
        "# Cleanup\n",
        "if current_pipe is not None:\n",
        "    del current_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nðŸŽ‰ ULTIMATE EXPERIMENT COMPLETED!\")\n",
        "print(f\"â±ï¸ Total time: {total_time}\")\n",
        "successful_results = sum(1 for r in all_results.values() if r.get('image') is not None)\n",
        "total_results = len(all_results)\n",
        "print(f\"ðŸ“Š Results: {successful_results:,}/{total_results:,} successful generations ({successful_results/total_results*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main Ultimate Testing Loop\n",
        "print(\"ðŸš€ Starting ULTIMATE comprehensive experiment...\")\n",
        "print(f\"â±ï¸ Testing {len(MODEL_CONFIGS)} models Ã— {len(SAMPLER_CONFIGS)} samplers Ã— {len(STEP_COUNTS)} steps Ã— {len(CFG_SCALES)} CFG scales Ã— {len(STRATEGY_CONFIGS)} strategies Ã— {len(test_prompts)} prompts\")\n",
        "\n",
        "# Store all results with enhanced structure\n",
        "all_results = {}\n",
        "current_pipe = None\n",
        "current_config = None\n",
        "generation_counter = 0\n",
        "\n",
        "start_time = datetime.now()\n",
        "print(f\"ðŸ• Experiment started at: {start_time}\")\n",
        "\n",
        "# Test each combination systematically\n",
        "for model_choice in MODEL_CONFIGS.keys():\n",
        "    print(f\"\\nðŸ¤– Testing model: {model_choice}\")\n",
        "    \n",
        "    for sampler_choice in SAMPLER_CONFIGS.keys():\n",
        "        print(f\"\\n  ðŸŽ›ï¸ Testing sampler: {sampler_choice}\")\n",
        "        \n",
        "        # Load pipeline with current sampler (reuse if same config)\n",
        "        config_key = f\"{model_choice}_{sampler_choice}\"\n",
        "        if current_config != config_key:\n",
        "            if current_pipe is not None:\n",
        "                del current_pipe\n",
        "                torch.cuda.empty_cache()\n",
        "            current_pipe = load_model_with_sampler(model_choice, sampler_choice)\n",
        "            current_config = config_key\n",
        "        \n",
        "        for steps in STEP_COUNTS:\n",
        "            print(f\"\\n    ðŸ“Š Testing {steps} steps...\")\n",
        "            \n",
        "            for cfg_scale in CFG_SCALES:\n",
        "                print(f\"\\n      âš™ï¸ Testing CFG scale {cfg_scale}...\")\n",
        "                \n",
        "                for strategy_name in STRATEGY_CONFIGS.keys():\n",
        "                    strategy_config = STRATEGY_CONFIGS[strategy_name]\n",
        "                    print(f\"\\n        ðŸŽ¯ Testing strategy: {strategy_name}\")\n",
        "                    \n",
        "                    for prompt_idx, original_prompt in enumerate(test_prompts, 1):\n",
        "                        generation_counter += 1\n",
        "                        \n",
        "                        # Apply strategy to prompt\n",
        "                        modified_prompt = strategy_config[\"modifier\"](original_prompt)\n",
        "                        \n",
        "                        print(f\"          ðŸ“ Prompt {prompt_idx}/8 ({generation_counter:,}/{total_combinations:,}): {original_prompt[:40]}...\")\n",
        "                        \n",
        "                        # Generate image\n",
        "                        image, gen_time, error = generate_with_config(\n",
        "                            current_pipe, modified_prompt, model_choice, steps, cfg_scale,\n",
        "                            seed=100 + prompt_idx  # Consistent seed per prompt\n",
        "                        )\n",
        "                        \n",
        "                        if image is not None:\n",
        "                            # Enhanced evaluation with both CLIP and aesthetic scores\n",
        "                            clip_results = analyze_image_with_clip(image)\n",
        "                            aesthetic_score = get_aesthetic_score(image)\n",
        "                            \n",
        "                            # Create comprehensive filename\n",
        "                            filename = f\"combined_experiment_results/{model_choice}_{sampler_choice}_{steps}s_{cfg_scale}cfg_{strategy_name}_p{prompt_idx:02d}.png\"\n",
        "                            image.save(filename)\n",
        "                            \n",
        "                            # Store comprehensive result\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': image,\n",
        "                                'filepath': filename,\n",
        "                                'generation_time': gen_time,\n",
        "                                'clip_top_label': clip_results[0][0],\n",
        "                                'clip_top_confidence': clip_results[0][1],\n",
        "                                'clip_results': clip_results,\n",
        "                                'laion_aesthetic_score': aesthetic_score,\n",
        "                                'error': None,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                            \n",
        "                            print(f\"            âœ… Generated in {gen_time:.1f}s | CLIP: {clip_results[0][0]} ({clip_results[0][1]:.3f}) | Aesthetic: {aesthetic_score:.2f}\")\n",
        "                            \n",
        "                        else:\n",
        "                            print(f\"            âŒ Failed: {error}\")\n",
        "                            result_key = f\"{model_choice}_{sampler_choice}_{steps}_{cfg_scale}_{strategy_name}_{prompt_idx}\"\n",
        "                            all_results[result_key] = {\n",
        "                                'model': model_choice,\n",
        "                                'sampler': sampler_choice,\n",
        "                                'steps': steps,\n",
        "                                'cfg_scale': cfg_scale,\n",
        "                                'strategy': strategy_name,\n",
        "                                'prompt_id': prompt_idx,\n",
        "                                'original_prompt': original_prompt,\n",
        "                                'modified_prompt': modified_prompt,\n",
        "                                'image': None,\n",
        "                                'filepath': None,\n",
        "                                'generation_time': gen_time,\n",
        "                                'error': error,\n",
        "                                'timestamp': datetime.now()\n",
        "                            }\n",
        "                        \n",
        "                        # Progress tracking\n",
        "                        if generation_counter % 100 == 0:\n",
        "                            elapsed = datetime.now() - start_time\n",
        "                            avg_time_per_gen = elapsed.total_seconds() / generation_counter\n",
        "                            remaining_time = (total_combinations - generation_counter) * avg_time_per_gen / 3600\n",
        "                            print(f\"\\nðŸ“ˆ Progress: {generation_counter:,}/{total_combinations:,} ({generation_counter/total_combinations*100:.1f}%)\")\n",
        "                            print(f\"â±ï¸ Elapsed: {elapsed} | Est. remaining: {remaining_time:.1f} hours\")\n",
        "\n",
        "# Cleanup\n",
        "if current_pipe is not None:\n",
        "    del current_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "end_time = datetime.now()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f\"\\nðŸŽ‰ ULTIMATE EXPERIMENT COMPLETED!\")\n",
        "print(f\"â±ï¸ Total time: {total_time}\")\n",
        "successful_results = sum(1 for r in all_results.values() if r.get('image') is not None)\n",
        "total_results = len(all_results)\n",
        "print(f\"ðŸ“Š Results: {successful_results:,}/{total_results:,} successful generations ({successful_results/total_results*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Arcade Assignment Jewelry Prompts\n",
        "arcade_prompts = [\n",
        "    \"channel-set diamond eternity band, 2 mm width, hammered 18k yellow gold, product-only white background\",\n",
        "    \"solitaire diamond engagement ring, round brilliant cut 1 carat, classic 6-prong setting, platinum band, product-only white background\", \n",
        "    \"three-stone engagement ring, emerald-cut center diamond with trilliant side stones, rose gold setting, product-only white background\",\n",
        "    \"vintage art deco engagement ring, cushion-cut diamond with milgrain detailing, white gold band, product-only white background\",\n",
        "    \"halo engagement ring, oval diamond surrounded by smaller diamonds, split shank band, yellow gold, product-only white background\",\n",
        "    \"tennis bracelet, round diamonds in 4-prong settings, 18k white gold, 7 inches long, product-only white background\",\n",
        "    \"diamond stud earrings, round brilliant cut, 4-prong settings, 18k yellow gold, product-only white background\",\n",
        "    \"pearl necklace, cultured freshwater pearls, 18-inch length, sterling silver clasp, product-only white background\"\n",
        "]\n",
        "\n",
        "print(\"ðŸ“ Loaded 8 Arcade Assignment Jewelry Prompts:\")\n",
        "for i, prompt in enumerate(arcade_prompts, 1):\n",
        "    print(f\"{i}. {prompt}\")\n",
        "\n",
        "# Generation parameters (following article recommendations)\n",
        "generation_params = {\n",
        "    \"width\": 512,\n",
        "    \"height\": 512,\n",
        "    \"num_inference_steps\": 20,  # Article recommends 20-40 steps\n",
        "    \"guidance_scale\": 7,  # CFG scale of 7\n",
        "    \"num_images_per_prompt\": 1\n",
        "}\n",
        "\n",
        "# Seeds for reproducibility (6 different seeds per technique per prompt)\n",
        "seeds = [42, 123, 456, 789, 999, 2024]\n",
        "\n",
        "print(f\"\\nâš™ï¸ Generation Parameters:\")\n",
        "for key, value in generation_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(f\"  Seeds: {seeds}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "\n",
        "def generate_images(prompt, technique_name, negative_prompt=\"\"):\n",
        "    \"\"\"Generate 6 images for a prompt using different seeds\"\"\"\n",
        "    images = []\n",
        "    \n",
        "    for i, seed in enumerate(seeds):\n",
        "        print(f\"    Generating image {i+1}/6 (seed: {seed})...\")\n",
        "        \n",
        "        # Set seed\n",
        "        generator = torch.Generator(device=device).manual_seed(seed)\n",
        "        \n",
        "        # Generate image\n",
        "        result = pipe(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            generator=generator,\n",
        "            **generation_params\n",
        "        )\n",
        "        \n",
        "        images.append(result.images[0])\n",
        "    \n",
        "    return images\n",
        "\n",
        "def create_grid_display(technique_name, prompts, all_images):\n",
        "    \"\"\"Create and display 8x7 grid: 8 prompts Ã— (1 text + 6 images)\"\"\"\n",
        "    fig, axes = plt.subplots(8, 7, figsize=(21, 24))\n",
        "    fig.suptitle(f'{technique_name}', fontsize=20, fontweight='bold', y=0.98)\n",
        "    \n",
        "    for row in range(8):\n",
        "        prompt = prompts[row]\n",
        "        images = all_images[row]\n",
        "        \n",
        "        # Column 0: Display prompt text\n",
        "        axes[row, 0].text(0.05, 0.5, f\"Prompt {row+1}:\\\\n{prompt[:100]}...\" if len(prompt) > 100 else f\"Prompt {row+1}:\\\\n{prompt}\",\n",
        "                         fontsize=8, ha='left', va='center', wrap=True, transform=axes[row, 0].transAxes)\n",
        "        axes[row, 0].axis('off')\n",
        "        \n",
        "        # Columns 1-6: Display generated images\n",
        "        for col in range(1, 7):\n",
        "            if col-1 < len(images):\n",
        "                axes[row, col].imshow(images[col-1])\n",
        "                axes[row, col].set_title(f\"Seed {seeds[col-1]}\", fontsize=8)\n",
        "            axes[row, col].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save the grid\n",
        "    save_path = os.path.join(output_dir, f\"{technique_name.lower().replace(' ', '_')}_grid.png\")\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "    print(f\"ðŸ’¾ Grid saved to: {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "def run_technique_experiment(technique_name, prompt_modifier_func, negative_prompt=\"\"):\n",
        "    \"\"\"Run a complete experiment for one technique\"\"\"\n",
        "    print(f\"\\\\nðŸŽ¨ {technique_name.upper()}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    all_images = []\n",
        "    \n",
        "    for i, base_prompt in enumerate(arcade_prompts):\n",
        "        print(f\"\\\\nðŸ“¿ Prompt {i+1}: {base_prompt[:50]}...\")\n",
        "        \n",
        "        # Apply technique-specific prompt modification\n",
        "        enhanced_prompt = prompt_modifier_func(base_prompt)\n",
        "        print(f\"ðŸ”§ Enhanced: {enhanced_prompt[:80]}...\")\n",
        "        \n",
        "        # Generate images for this prompt\n",
        "        images = generate_images(enhanced_prompt, technique_name, negative_prompt)\n",
        "        all_images.append(images)\n",
        "    \n",
        "    # Create and display grid\n",
        "    create_grid_display(technique_name, \n",
        "                       [prompt_modifier_func(p) for p in arcade_prompts], \n",
        "                       all_images)\n",
        "    \n",
        "    return all_images\n",
        "\n",
        "print(\"âœ… Utility functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 1: Baseline Prompts\n",
        "**Original prompts without any enhancement - establishing the control group**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 1: Baseline - No modifications\n",
        "def baseline_modifier(prompt):\n",
        "    return prompt\n",
        "\n",
        "baseline_results = run_technique_experiment(\"Technique 1: Baseline Prompts\", baseline_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 2: Medium Enhancement\n",
        "**Adding photography medium specifications to make prompts more specific**\n",
        "- Ultra-realistic photography\n",
        "- Professional product photography\n",
        "- High-end jewelry photography\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 2: Medium Enhancement\n",
        "def medium_modifier(prompt):\n",
        "    return f\"Ultra-realistic professional jewelry photography of {prompt}\"\n",
        "\n",
        "medium_results = run_technique_experiment(\"Technique 2: Medium Enhancement\", medium_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 3: Artistic Style Enhancement  \n",
        "**Adding artistic style keywords to influence the aesthetic**\n",
        "- Hyperrealistic style\n",
        "- Luxury commercial photography style\n",
        "- Modern minimalist aesthetic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 3: Artistic Style Enhancement\n",
        "def artistic_style_modifier(prompt):\n",
        "    return f\"Hyperrealistic luxury commercial photography style, modern minimalist aesthetic, {prompt}\"\n",
        "\n",
        "artistic_results = run_technique_experiment(\"Technique 3: Artistic Style Enhancement\", artistic_style_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 4: Famous Artists Enhancement\n",
        "**Including renowned photographer/artist names for style influence**\n",
        "- Annie Leibovitz (famous portrait photographer)\n",
        "- Irving Penn (master of still life photography)  \n",
        "- Richard Avedon (iconic fashion photographer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 4: Famous Artists Enhancement\n",
        "def artist_modifier(prompt):\n",
        "    return f\"{prompt}, by Annie Leibovitz and Irving Penn, in the style of Richard Avedon\"\n",
        "\n",
        "artist_results = run_technique_experiment(\"Technique 4: Famous Artists Enhancement\", artist_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 5: Website References Enhancement\n",
        "**Adding platform names that are known for high-quality imagery**\n",
        "- ArtStation (digital art platform)\n",
        "- Behance (creative portfolio platform)\n",
        "- Professional photography websites\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 5: Website References Enhancement\n",
        "def website_modifier(prompt):\n",
        "    return f\"{prompt}, ArtStation, Behance, professional jewelry photography portfolio\"\n",
        "\n",
        "website_results = run_technique_experiment(\"Technique 5: Website References Enhancement\", website_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 6: Resolution Enhancement\n",
        "**Adding high-quality descriptors for detailed output**\n",
        "- 4K, 8K resolution specifications\n",
        "- Sharp focus, highly detailed\n",
        "- Professional quality indicators\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 6: Resolution Enhancement\n",
        "def resolution_modifier(prompt):\n",
        "    return f\"{prompt}, 4K, 8K, highly detailed, sharp focus, professional quality, ultra-detailed\"\n",
        "\n",
        "resolution_results = run_technique_experiment(\"Technique 6: Resolution Enhancement\", resolution_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 7: Lighting Enhancement\n",
        "**Adding professional lighting techniques for better visual appeal**\n",
        "- Rim lighting, studio lighting\n",
        "- Cinematic lighting, soft lighting\n",
        "- Professional jewelry photography lighting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 7: Lighting Enhancement\n",
        "def lighting_modifier(prompt):\n",
        "    return f\"{prompt}, professional studio lighting, rim lighting, soft diffused lighting, cinematic lighting\"\n",
        "\n",
        "lighting_results = run_technique_experiment(\"Technique 7: Lighting Enhancement\", lighting_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 8: Color Enhancement\n",
        "**Adding specific color guidance for better color accuracy**\n",
        "- Brilliant colors, vibrant colors\n",
        "- True-to-life metal tones\n",
        "- Accurate gemstone colors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 8: Color Enhancement\n",
        "def color_modifier(prompt):\n",
        "    return f\"{prompt}, brilliant colors, vibrant, true-to-life metal tones, accurate color representation\"\n",
        "\n",
        "color_results = run_technique_experiment(\"Technique 8: Color Enhancement\", color_modifier)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 9: Negative Prompts Enhancement\n",
        "**Using negative prompts to specify what should NOT be in the image**\n",
        "Based on the article's recommended negative prompt template for high-quality outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 9: Negative Prompts Enhancement\n",
        "def negative_modifier(prompt):\n",
        "    return prompt\n",
        "\n",
        "# Comprehensive negative prompt from the article, adapted for jewelry\n",
        "jewelry_negative_prompt = \"\"\"(worst quality, low quality, normal quality, low-res, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, CGI, render, blender, digital art, manga, amateur:1.3), (bad hands, bad anatomy, bad jewelry, deformed jewelry, fake looking, plastic, cheap:1.3), multiple objects, cluttered, messy background\"\"\"\n",
        "\n",
        "negative_results = run_technique_experiment(\"Technique 9: Negative Prompts Enhancement\", negative_modifier, jewelry_negative_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”¬ Technique 10: Keyword Emphasis Enhancement\n",
        "**Using weighting factors to emphasize important keywords**\n",
        "Using the article's (keyword:factor) syntax to emphasize crucial jewelry terms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Technique 10: Keyword Emphasis Enhancement\n",
        "def emphasis_modifier(prompt):\n",
        "    # Add emphasis to important jewelry terms using (keyword:factor) syntax\n",
        "    emphasized_prompt = prompt.replace(\"diamond\", \"(diamond:1.3)\")\n",
        "    emphasized_prompt = emphasized_prompt.replace(\"gold\", \"(gold:1.2)\")\n",
        "    emphasized_prompt = emphasized_prompt.replace(\"platinum\", \"(platinum:1.2)\")\n",
        "    emphasized_prompt = emphasized_prompt.replace(\"engagement ring\", \"(engagement ring:1.2)\")\n",
        "    emphasized_prompt = emphasized_prompt.replace(\"product-only white background\", \"(product-only white background:1.4)\")\n",
        "    return emphasized_prompt\n",
        "\n",
        "emphasis_results = run_technique_experiment(\"Technique 10: Keyword Emphasis Enhancement\", emphasis_modifier, jewelry_negative_prompt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Experiment Summary\n",
        "**Comprehensive results from all 10 prompting techniques**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ðŸŽ‰ EXPERIMENT COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"âœ… Generated 480 images total (8 prompts Ã— 6 seeds Ã— 10 techniques)\")\n",
        "print(\"âœ… Created 10 comprehensive grids (8Ã—7 layout)\")\n",
        "print(\"âœ… Tested all major prompting techniques from Machine Learning Mastery article\")\n",
        "\n",
        "print(\"\\\\nðŸ“ Generated Files:\")\n",
        "print(f\"ðŸ“‚ Output directory: {output_dir}\")\n",
        "print(\"ðŸ“„ Grid images saved as: technique_name_grid.png\")\n",
        "\n",
        "print(\"\\\\nðŸ” Techniques Tested:\")\n",
        "techniques = [\n",
        "    \"1. Baseline Prompts\",\n",
        "    \"2. Medium Enhancement\", \n",
        "    \"3. Artistic Style Enhancement\",\n",
        "    \"4. Famous Artists Enhancement\",\n",
        "    \"5. Website References Enhancement\",\n",
        "    \"6. Resolution Enhancement\",\n",
        "    \"7. Lighting Enhancement\", \n",
        "    \"8. Color Enhancement\",\n",
        "    \"9. Negative Prompts Enhancement\",\n",
        "    \"10. Keyword Emphasis Enhancement\"\n",
        "]\n",
        "\n",
        "for technique in techniques:\n",
        "    print(f\"   âœ“ {technique}\")\n",
        "\n",
        "print(\"\\\\nðŸŽ¯ Key Insights:\")\n",
        "print(\"â€¢ Compare grids to see which techniques work best for jewelry\")\n",
        "print(\"â€¢ Look for improved detail, lighting, and realism\")\n",
        "print(\"â€¢ Notice differences in background quality and product focus\")\n",
        "print(\"â€¢ Evaluate which approaches produce most professional results\")\n",
        "\n",
        "print(\"\\\\nðŸ“Š Next Steps:\")\n",
        "print(\"â€¢ Analyze the generated grids visually\")\n",
        "print(\"â€¢ Identify the most effective techniques\")\n",
        "print(\"â€¢ Combine the best techniques for optimal prompts\")\n",
        "print(\"â€¢ Apply learnings to future jewelry generation tasks\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
